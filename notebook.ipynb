{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carla speed limit assist with corrective actions and traffic light detection and warning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import library\n",
    "- **cv2 (OpenCV):** computer vision library for image processing. Used for handling and processing video frames or images.\n",
    "- **paho.mqtt.client:** client library for the MQTT protocol, this library permit to publish MQTT topics, likely for exchanging data between the CARLA simulator and other systems.\n",
    "- **ultralytics (YOLO):** provides Python interface for the YOLO (You Only Look Once) object detection framework. It provide object detection tasks, such as identify traffic light, speedLimit.\n",
    "- **pygame:** library for creating games and multimedia applications, it allows to take input events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import paho.mqtt.client as mqtt\n",
    "from ultralytics import YOLO\n",
    "import time\n",
    "import pygame\n",
    "\n",
    "try:\n",
    "    sys.path.append(glob.glob('../../carla/dist/carla-*%d.%d-%s.egg' % (\n",
    "        sys.version_info.major,\n",
    "        sys.version_info.minor,\n",
    "        'win-amd64' if os.name == 'nt' else 'linux-x86_64'))[0])\n",
    "except IndexError:\n",
    "    pass\n",
    "\n",
    "import carla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broker MQTT configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BROKER = \"localhost\"\n",
    "PORT = 1883    \n",
    "\n",
    "clientMQTT = mqtt.Client()\n",
    "clientMQTT.connect(BROKER, PORT, 60)\n",
    "def sendEventToBroker(topic, message):\n",
    "    try:\n",
    "        clientMQTT.publish(topic, message)\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Client configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = carla.Client('localhost', 2000)\n",
    "client.set_timeout(10.0)\n",
    "client.load_world('Town02')\n",
    "world = client.get_world()\n",
    "spectator = world.get_spectator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpful functions used in this notebook\n",
    "- **spawn_vehicle:** Adds a vehicle to the simulation.\n",
    "  - Picks a vehicle type from the blueprint library (pattern).\n",
    "  - Selects a spawn point on the map (spawn_index).\n",
    "  - Places the vehicle at that location.\n",
    "- **spawn_camera** Adds a camera to the simulation.\n",
    "  - Sets the camera size, field of view (foV), and update speed.\n",
    "  - Places the camera at a specific position and angle.\n",
    "  - Attaches the camera to a vehicle.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 640\n",
    "currect_map = False\n",
    "\n",
    "def spawn_vehicle(vehicle_index=0, spawn_index=0, pattern='vehicle.*'):\n",
    "    blueprint_library = world.get_blueprint_library()\n",
    "    vehicle_bp = blueprint_library.filter(pattern)[vehicle_index]\n",
    "    spawn_point = world.get_map().get_spawn_points()[spawn_index]\n",
    "    vehicle = world.spawn_actor(vehicle_bp, spawn_point)\n",
    "    return vehicle\n",
    "\n",
    "if world.get_map().name == \"Town02\" or world.get_map().name == \"Town01\":\n",
    "    currect_map = True\n",
    "\n",
    "def spawn_camera(attach_to=None, transform=carla.Transform(carla.Location(x=0.7, z=1.8), carla.Rotation(pitch=5, yaw=35)), width=IMAGE_SIZE, height=IMAGE_SIZE, foV=50):\n",
    "    camera_bp = world.get_blueprint_library().find('sensor.camera.rgb')\n",
    "    camera_bp.set_attribute('image_size_x', str(width))\n",
    "    camera_bp.set_attribute('image_size_y', str(height))\n",
    "    camera_bp.set_attribute('fov', str(foV))\n",
    "    camera_bp.set_attribute('sensor_tick', '0')\n",
    "    camera = world.spawn_actor(camera_bp, transform, attach_to=attach_to)\n",
    "    return camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training YOLOv8 Models for Object Detection\n",
    "\n",
    "### Overview\n",
    "We have trained the **YOLOv8** model multiple times to detect specific objects with two categories:\n",
    "\n",
    "1. **Speed Limits**:\n",
    "    - **First Training**: Using images of the speed limit signs without any background.\n",
    "    - **Second Training**: Using images of speed limit signs in real-world environments, with significant background clutter for object detection.\n",
    "\n",
    "2. **Traffic Lights**:\n",
    "    - **First Training**: Using images of the traffic lights without any background.\n",
    "    - **Second Training**: Using images of traffic lights in real-world environments, with significant background clutter for object detection.\n",
    "\n",
    "At the end, we will have **two YOLOv8 models**:\n",
    "- One dedicated to **speed limits**.\n",
    "- One dedicated to **traffic lights**.\n",
    "\n",
    "### Dataset\n",
    "The datasets used for training were sourced from the following site:  \n",
    "[Roboflow Universe](https://universe.roboflow.com/)\n",
    "\n",
    "### Base Code for Downloading and Training the Model\n",
    "Below is the base code to download the dataset and train the YOLOv8 model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install roboflow\n",
    "# from roboflow import Roboflow\n",
    "# rf = Roboflow(api_key=\"...\")\n",
    "# project = rf.workspace(\"wawan-pradana\").project(\"cinta_v2\")\n",
    "# dataset = project.version(1).download(\"yolov8\")\n",
    "# model = YOLO('yolov8n.pt')\n",
    "# results = model.train(data=\"data.yaml\", epochs=80, imgsz=416, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model Results\n",
    "<img src=\"runsSpeed/detect/train/confusion_matrix.png\" alt=\"Descrizione dell'immagine\" width=\"700\">\n",
    "<img src=\"runsTrafficLight/detect/train3/confusion_matrix.png\" alt=\"Descrizione dell'immagine\" width=\"700\">\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pretrained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE_SPEED = 416\n",
    "model = YOLO(\"runsSpeed/detect/train/weights/best.pt\")\n",
    "modelTrafficLight = YOLO(\"runsTrafficLight/detect/train3/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set weather conditions\n",
    "- Set the worst weather condition or the best weather condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = world.get_weather()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.sun_azimuth_angle = 0\n",
    "weather.sun_altitude_angle = -90\n",
    "weather.cloudiness = 100\n",
    "weather.precipitation = 100\n",
    "weather.precipitation_deposits = 100\n",
    "weather.wind_intensity = 100\n",
    "weather.fog_density = 100\n",
    "weather.fog_distance = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.sun_azimuth_angle = 0 \n",
    "weather.sun_altitude_angle = 90\n",
    "weather.cloudiness = 20\n",
    "weather.precipitation = 0\n",
    "weather.precipitation_deposits = 0\n",
    "weather.wind_intensity = 0\n",
    "weather.fog_density = 30\n",
    "weather.fog_distance = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.set_weather(weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorSpeedLimit(current_speed, speed_limit):\n",
    "    if speed_limit == None or int(current_speed) <= int(speed_limit):\n",
    "        return (0, 255, 0) \n",
    "    else:\n",
    "        return (0, 0, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcColor():\n",
    "    if traffic_light == \"red\":\n",
    "        return (0, 0, 255)\n",
    "    elif traffic_light == \"yellow\":\n",
    "        return (0, 255, 255)\n",
    "    elif traffic_light == \"green\":\n",
    "        return (0, 255, 0)\n",
    "    else:\n",
    "        return (255, 255, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camera_callback(image):\n",
    "    global last_analysis_time, last_speed_limit\n",
    "    # Ottieni il timestamp attuale\n",
    "    current_time = time.time()\n",
    "\n",
    "    # Converti l'immagine raw in un array NumPy\n",
    "    array = np.frombuffer(image.raw_data, dtype=np.uint8)\n",
    "    # Assicurati che l'immagine abbia il formato BGRA (4 canali)\n",
    "    image_np = array.reshape((IMAGE_SIZE, IMAGE_SIZE, 4))  # Immagine BGRA\n",
    "    image_bgr = image_np[:, :, :3]  \n",
    "    resized_image = cv2.resize(image_bgr, (IMAGE_SIZE_SPEED, IMAGE_SIZE_SPEED), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # Verifica se è passato almeno 1 secondo dall'ultima analisi\n",
    "    if current_time - last_analysis_time >= analysis_interval:\n",
    "        last_analysis_time = current_time  # Aggiorna il timestamp\n",
    "\n",
    "        # Rileva gli oggetti nell'immagine\n",
    "        results = model(resized_image)\n",
    "        \n",
    "\n",
    "        limit_id = None\n",
    "        confidence_max = 0\n",
    "\n",
    "            # Class IDs\n",
    "        class_ids = results[0].boxes.cls.numpy()\n",
    "        confidences = results[0].boxes.conf.numpy()\n",
    "        \n",
    "        for class_id, confidence in zip(class_ids, confidences):\n",
    "            if confidence > confidence_max:\n",
    "                limit_id = class_id\n",
    "                confidence_max = confidence\n",
    "\n",
    "        if confidence_max > 0.87:\n",
    "            print(confidence_max)\n",
    "            class_name = class_names[int(limit_id)]  # Ottieni il nome della classe\n",
    "            try:\n",
    "                last_speed_limit = class_name.split(\" \")[2]  # Usa confidenza come esempio\n",
    "                sendEventToBroker(\"speedLimit\", \"Detected \" + last_speed_limit)\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camera_view_callback(image):\n",
    "    global video_output, speed_car\n",
    "    # Converti l'immagine raw in un array NumPy\n",
    "    array = np.frombuffer(image.raw_data, dtype=np.uint8)\n",
    "    # Assicurati che l'immagine abbia il formato BGRA (4 canali)\n",
    "    image_np = array.reshape((IMAGE_SIZE, IMAGE_SIZE, 4))  # Immagine BGRA\n",
    "    velocity_car = vehicle.get_velocity()\n",
    "    speed_car = 3.6 * (velocity_car.x**2 + velocity_car.y**2 + velocity_car.z**2)**0.5  # Conversione da m/s a km/h\n",
    "    video_output = image_np  # Mantieni il frame per visualizzazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camera_traffic_callback(image):\n",
    "    global last_analysis_time_trafficLight, traffic_light\n",
    "    # Ottieni il timestamp attuale\n",
    "    current_time = time.time()\n",
    "\n",
    "    # Converti l'immagine raw in un array NumPy\n",
    "    array = np.frombuffer(image.raw_data, dtype=np.uint8)\n",
    "    # Assicurati che l'immagine abbia il formato BGRA (4 canali)\n",
    "    image_np = array.reshape((IMAGE_SIZE, IMAGE_SIZE, 4))  # Immagine BGRA\n",
    "    image_bgr = image_np[:, :, :3].copy()  # Crea una copia modificabile dell'immagine BGR\n",
    "    # Determina la frazione dell'immagine che vuoi oscurare\n",
    "    fraction_to_black = 0.1  # Per esempio, il 20% inferiore dell'immagine\n",
    "    height = image_bgr.shape[0]\n",
    "    black_start_row = int(height * (1 - fraction_to_black))\n",
    "    image_bgr[black_start_row:, :] = 0  # Imposta a nero (0, 0, 0)\n",
    "    image_bgr[:, 500:] = 0\n",
    "    #resized_image = cv2.resize(image_bgr, (IMAGE_SIZE_SPEED, IMAGE_SIZE_SPEED), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    accentuated_image = image_bgr.copy()\n",
    "\n",
    "    # Aumenta il canale Rosso\n",
    "    accentuated_image[:, :, 2] = cv2.add(accentuated_image[:, :, 2], 15)  # Aumenta Rosso (+50)\n",
    "\n",
    "    # Riduci il canale Verde\n",
    "    accentuated_image[:, :, 1] = cv2.subtract(accentuated_image[:, :, 1], 0)  # Riduci Verde (-30)\n",
    "\n",
    "    # Riduci il canale Blu\n",
    "    accentuated_image[:, :, 0] = cv2.subtract(accentuated_image[:, :, 0], 20)  # Riduci Blu (-30)\n",
    "\n",
    "    # Assicurati che i valori restino nel range [0, 255]\n",
    "    resized_image = np.clip(accentuated_image, 0, 255).astype(np.uint8)\n",
    "\n",
    "    # Verifica se è passato almeno 1 secondo dall'ultima analisi\n",
    "    if current_time - last_analysis_time_trafficLight >= analysis_interval_trafficLight:\n",
    "        last_analysis_time_trafficLight = current_time  # Aggiorna il timestamp\n",
    "\n",
    "        # Rileva gli oggetti nell'immagine\n",
    "        results = modelTrafficLight(resized_image)\n",
    "\n",
    "        trafficLight_id = None\n",
    "        confidence_max = 0\n",
    "\n",
    "        # Class IDs\n",
    "        class_ids = results[0].boxes.cls.numpy()\n",
    "        confidences = results[0].boxes.conf.numpy()\n",
    "\n",
    "        if class_ids.size == 0:\n",
    "            traffic_light = \"Non individuato\"\n",
    "        else:\n",
    "            for class_id, confidence in zip(class_ids, confidences):\n",
    "                if confidence > confidence_max:\n",
    "                    trafficLight_id = class_id\n",
    "                    confidence_max = confidence\n",
    "\n",
    "            if class_names_trafficLight[int(trafficLight_id)] == \"yellow\" and class_name == \"red\":\n",
    "                class_name = \"red\"\n",
    "            else:\n",
    "                class_name = class_names_trafficLight[int(trafficLight_id)]\n",
    "            if confidence_max > 0.62 and class_name==\"red\" or confidence_max > 0.45 and class_name!=\"red\":\n",
    "                if traffic_light != class_name:\n",
    "                    traffic_light = class_name\n",
    "                    sendEventToBroker(\"TrafficLight\", \"Detected trafficlight \" + class_name)\n",
    "                print(confidence_max)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camera_traffic_red_callback(image):\n",
    "    global last_analysis_time_trafficLight_red, red_over\n",
    "    current_time = time.time()\n",
    "    array = np.frombuffer(image.raw_data, dtype=np.uint8)\n",
    "    image_np = array.reshape((IMAGE_SIZE, IMAGE_SIZE, 4))  # Immagine BGRA\n",
    "    image_bgr = image_np[:, :, :3].copy()  # Crea una copia modificabile dell'immagine BGR\n",
    "\n",
    "    accentuated_image = image_bgr.copy()\n",
    "\n",
    "    # Aumenta il canale Rosso\n",
    "    accentuated_image[:, :, 2] = cv2.add(accentuated_image[:, :, 2], 16)  # Aumenta Rosso (+50)\n",
    "\n",
    "    # Riduci il canale Verde\n",
    "    accentuated_image[:, :, 1] = cv2.subtract(accentuated_image[:, :, 1], 0)  # Riduci Verde (-30)\n",
    "\n",
    "    # Riduci il canale Blu\n",
    "    accentuated_image[:, :, 0] = cv2.subtract(accentuated_image[:, :, 0], 20)  # Riduci Blu (-30)\n",
    "\n",
    "    # Assicurati che i valori restino nel range [0, 255]\n",
    "    resized_image = np.clip(accentuated_image, 0, 255).astype(np.uint8)\n",
    "\n",
    "    # Verifica se è passato almeno 1 secondo dall'ultima analisi\n",
    "    if current_time - last_analysis_time_trafficLight_red >= analysis_interval_trafficLight_red:\n",
    "        last_analysis_time_trafficLight_red = current_time  # Aggiorna il timestamp\n",
    "\n",
    "        # Rileva gli oggetti nell'immagine\n",
    "        results = modelTrafficLight(resized_image)\n",
    "\n",
    "        trafficLight_id = None\n",
    "        confidence_max = 0\n",
    "\n",
    "        # Class IDs\n",
    "        class_ids = results[0].boxes.cls.numpy()\n",
    "        confidences = results[0].boxes.conf.numpy()\n",
    "\n",
    "        if class_ids.size != 0:\n",
    "            for class_id, confidence in zip(class_ids, confidences):\n",
    "                if confidence > confidence_max:\n",
    "                    trafficLight_id = class_id\n",
    "                    confidence_max = confidence\n",
    "\n",
    "            class_name = class_names_trafficLight[int(trafficLight_id)]\n",
    "            if class_name==\"red\" and confidence_max > 0.62:\n",
    "                if(gear != \"Reverse\" and not red_over): # Freniamo solo se andiamo sotto ai 50km/h\n",
    "                    red_over = True\n",
    "            elif (class_name==\"green\" or class_name==\"yellow\") and confidence_max > 0.43:\n",
    "                red_over = False\n",
    "        else:\n",
    "            red_over = False\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display = pygame.display.set_mode((50, 50))\n",
    "pygame.display.set_caption(\"Controllo Manuale CARLA\")\n",
    "\n",
    "# Velocità di sterzo e accelerazione\n",
    "steer_increment = 0.02\n",
    "throttle_increment = 0.1\n",
    "steer = 0.0\n",
    "throttle = 0.0\n",
    "brake = 0.0\n",
    "global gear \n",
    "gear = \"Drive\"  # Stato iniziale (marcia avanti)\n",
    "speed_control_activate = False\n",
    "red_over_activate = False\n",
    "red_over = False\n",
    "\n",
    "# Costanti del controllore proporzionale\n",
    "KP_THROTTLE = 0.15  # Guadagno proporzionale per accelerazione\n",
    "KP_BRAKE = 0.02    # Guadagno proporzionale per frenata\n",
    "DEAD_ZONE = 3.0    # Zona morta attorno al limite di velocità\n",
    "MIN_THROTTLE = 0.2  # Soglia minima di accelerazione\n",
    "MIN_BRAKE = 0.1     # Soglia minima di frenata\n",
    "\n",
    "# Variabile per tenere traccia del tempo dell'ultima analisi\n",
    "last_analysis_time = 0  # Inizializza l'ultima analisi a 0 secondi\n",
    "last_analysis_time_trafficLight = 0\n",
    "last_analysis_time_trafficLight_red = 0\n",
    "analysis_interval = 0.2  # Intervallo in secondi tra le analisi\n",
    "analysis_interval_trafficLight = 0.4\n",
    "analysis_interval_trafficLight_red = 0.5\n",
    "\n",
    "# Inizializza il frame di output\n",
    "video_output = np.zeros((IMAGE_SIZE, IMAGE_SIZE, 3), dtype=np.uint8)\n",
    "\n",
    "# Variabile per tenere traccia dell'ultimo limite di velocità\n",
    "last_speed_limit = None\n",
    "speed_car = 0\n",
    "traffic_light = \"None\"\n",
    "\n",
    "class_names = model.names \n",
    "class_names_trafficLight = modelTrafficLight.names\n",
    "\n",
    "vehicle = spawn_vehicle()\n",
    "\n",
    "camera = spawn_camera(attach_to=vehicle)\n",
    "camera.listen(lambda image: camera_callback(image))\n",
    "\n",
    "camera_view = spawn_camera(attach_to=vehicle, transform=carla.Transform(carla.Location(x=1, z=1.5), carla.Rotation(pitch=0, yaw=0)), width=IMAGE_SIZE, height=IMAGE_SIZE, foV=90)\n",
    "camera_view.listen(lambda image: camera_view_callback(image))\n",
    "\n",
    "if currect_map:\n",
    "    camera_trafficLight = spawn_camera(attach_to=vehicle, transform=carla.Transform(carla.Location(x=0, y=1 , z=1.2), carla.Rotation(pitch=20, yaw=20)), width=IMAGE_SIZE, height=IMAGE_SIZE, foV=45)\n",
    "    camera_trafficLight.listen(lambda image: camera_traffic_callback(image))\n",
    "    camera_trafficLight_red_detector = spawn_camera(attach_to=vehicle, transform=carla.Transform(carla.Location(x=-1.8, y=0 , z=2), carla.Rotation(pitch=0, yaw=0)), width=IMAGE_SIZE, height=IMAGE_SIZE, foV=110)\n",
    "    camera_trafficLight_red_detector.listen(lambda image: camera_traffic_red_callback(image))\n",
    "\n",
    "\n",
    "\n",
    "# Mostra i risultati\n",
    "cv2.namedWindow('RGB Camera', cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "try:\n",
    "    clock = pygame.time.Clock()\n",
    "    event_timer = 0  # Per controllare la frequenza di gestione eventi\n",
    "    EVENT_RATE = 100  # Gestione eventi ogni 100 ms (10 volte al secondo)\n",
    "    while True:\n",
    "        # Aggiungi testo all'immagine\n",
    "        temp_frame = video_output.copy()\n",
    "        cv2.putText(\n",
    "            temp_frame,\n",
    "            f\"Last Speed Limit: {last_speed_limit}\",\n",
    "            (10, 20),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.5,\n",
    "            (0, 255, 0),\n",
    "            2,\n",
    "            cv2.LINE_AA,\n",
    "        )\n",
    "        cv2.putText(\n",
    "            temp_frame,\n",
    "            f\"Current speed: {speed_car:.0f}\",\n",
    "            (10, 45),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.5,\n",
    "            colorSpeedLimit(speed_car, last_speed_limit),\n",
    "            2,\n",
    "            cv2.LINE_AA,\n",
    "        )\n",
    "\n",
    "        if currect_map:\n",
    "            if red_over:\n",
    "                val = \"Sei passato col rosso\"\n",
    "                sendEventToBroker(\"Semaforo\", \"Ran red light\")\n",
    "            else:\n",
    "                val = \"\"\n",
    "            cv2.putText(\n",
    "                temp_frame,\n",
    "                val,\n",
    "                (10, 100),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.5,\n",
    "                (0,0,255),\n",
    "                2,\n",
    "                cv2.LINE_AA,\n",
    "            )\n",
    "        cv2.putText(\n",
    "            temp_frame,\n",
    "            f\"Trafficlight: {traffic_light}\",\n",
    "            (10, 70),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.5,\n",
    "            calcColor(),\n",
    "            2,\n",
    "            cv2.LINE_AA,\n",
    "        )\n",
    "            \n",
    "        # Mostra il frame con il testo\n",
    "        cv2.imshow('RGB Camera', temp_frame)\n",
    "        # Interrompi con il tasto 'q'\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "\n",
    "\n",
    "        current_time = pygame.time.get_ticks()\n",
    "        if current_time - event_timer > EVENT_RATE:\n",
    "            event_timer = current_time  # Aggiorna il timer\n",
    "            # Gestione eventi pygame\n",
    "            for event in pygame.event.get():\n",
    "                if event.type == pygame.QUIT:\n",
    "                    break\n",
    "                elif event.type == pygame.KEYUP:  # Rileva il rilascio del tasto\n",
    "                    if event.key == pygame.K_e:\n",
    "                        speed_control_activate = not speed_control_activate\n",
    "                    if event.key == pygame.K_c:\n",
    "                        vehicle.set_autopilot(True)\n",
    "                    if event.key == pygame.K_v:\n",
    "                        vehicle.set_autopilot(False)\n",
    "                    if event.key == pygame.K_o:\n",
    "                        red_over_activate = not red_over_activate\n",
    "\n",
    "            keys = pygame.key.get_pressed()  # Leggi i tasti premuti\n",
    "\n",
    "            if speed_control_activate and last_speed_limit and keys[pygame.K_w]:\n",
    "                # Calcolo l'errore rispetto al limite\n",
    "                error = float(last_speed_limit) - float(speed_car) + 3\n",
    "\n",
    "                if error < -DEAD_ZONE:  # Sopra il limite di velocità + zona morta\n",
    "                    throttle = 0\n",
    "                    brake = max(KP_BRAKE * abs(error), MIN_BRAKE)\n",
    "                else:  # Sotto o entro il limite + zona morta\n",
    "                    throttle = max(KP_THROTTLE * error, MIN_THROTTLE)\n",
    "                    brake = 0\n",
    "            elif keys[pygame.K_w]:\n",
    "                # Controllo manuale per accelerare\n",
    "                throttle = min(throttle + throttle_increment, 1)\n",
    "                brake = 0\n",
    "            else:\n",
    "                throttle = 0\n",
    "                brake = 0\n",
    "            \n",
    "            if keys[pygame.K_s]:  # Controllo manuale per frenare\n",
    "                brake = min(brake + throttle_increment*4, 1)\n",
    "                throttle = 0\n",
    "\n",
    "            if red_over and int(speed_car) <= 40 and gear != \"Reverse\" and red_over_activate:\n",
    "                brake = 1\n",
    "                throttle = 0\n",
    "\n",
    "            # Controllo sterzo\n",
    "            if keys[pygame.K_r]:  # Imposta retromarcia\n",
    "                gear = \"Reverse\"\n",
    "                red_over = False\n",
    "            elif keys[pygame.K_f]:  # Imposta marcia avanti\n",
    "                gear = \"Drive\"\n",
    "            elif keys[pygame.K_a]:  # Sterza a sinistra\n",
    "                steer = max(steer - steer_increment, -1)\n",
    "            elif keys[pygame.K_d]:  # Sterza a destra\n",
    "                steer = min(steer + steer_increment, 1)\n",
    "            else:\n",
    "                steer = steer * 0.9  # Ritorno al centro graduale\n",
    "\n",
    "            # Applicazione dei controlli\n",
    "            control = carla.VehicleControl()\n",
    "            control.throttle = throttle\n",
    "            control.brake = brake\n",
    "            control.steer = steer\n",
    "            if gear == \"Reverse\":\n",
    "                control.reverse = True\n",
    "            else:\n",
    "                control.reverse = False\n",
    "            vehicle.apply_control(control)\n",
    "\n",
    "        clock.tick(40)\n",
    "finally:\n",
    "    cv2.destroyAllWindows()\n",
    "    pygame.quit()\n",
    "    camera.destroy()\n",
    "    camera_trafficLight.destroy()\n",
    "    camera_trafficLight_red_detector.destroy()\n",
    "    camera_view.destroy()\n",
    "    vehicle.destroy()\n",
    "    clientMQTT.disconnect()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carla-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

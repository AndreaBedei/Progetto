{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carla speed limit assist with corrective actions and traffic light detection and warning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing of libraries\n",
    "- **cv2 (OpenCV):** computer vision library for image processing. Used for handling and processing video frames or images.\n",
    "- **paho.mqtt.client:** client library for the MQTT protocol, this library permit to publish MQTT topics, likely for exchanging data between the CARLA simulator and other systems.\n",
    "- **ultralytics (YOLO):** provides Python interface for the YOLO (You Only Look Once) object detection framework. It provide object detection tasks, such as identify traffic light, speedLimit.\n",
    "- **pygame:** library for creating games and multimedia applications, it allows to take input events.\n",
    "- **screeninfo:** To retrieve monitor specifications, likely for adjusting the display settings of the simulation or output windows.\n",
    "- **ConfigParser:** For reading configuration files, potentially used to manage simulation settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import paho.mqtt.client as mqtt\n",
    "from ultralytics import YOLO\n",
    "from screeninfo import get_monitors\n",
    "import time\n",
    "from configparser import ConfigParser\n",
    "import math\n",
    "import pygame\n",
    "\n",
    "try:\n",
    "    sys.path.append(glob.glob('../../carla/dist/carla-*%d.%d-%s.egg' % (\n",
    "        sys.version_info.major,\n",
    "        sys.version_info.minor,\n",
    "        'win-amd64' if os.name == 'nt' else 'linux-x86_64'))[0])\n",
    "except IndexError:\n",
    "    pass\n",
    "\n",
    "import carla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function determines the dimensions of the largest monitor available on the system. It uses the get_monitors function from the screeninfo library to retrieve information about all connected monitors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larghezza dello schermo più grande: 5120\n",
      "Altezza dello schermo più grande: 1440\n"
     ]
    }
   ],
   "source": [
    "width_screen = 0\n",
    "height_screen = 0\n",
    "\n",
    "def get_screen_dimensions():\n",
    "    global width_screen, height_screen\n",
    "    monitors = get_monitors()\n",
    "    for monitor in monitors:\n",
    "        if width_screen < monitor.width:\n",
    "            width_screen = monitor.width\n",
    "            height_screen = monitor.height\n",
    "\n",
    "get_screen_dimensions()\n",
    "print(f\"Larghezza dello schermo più grande: {width_screen}\")\n",
    "print(f\"Altezza dello schermo più grande: {height_screen}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broker MQTT configuration\n",
    "This code sets up an MQTT client to securely connect to a broker using the HiveMQ Cloud service and send messages to specific topics, in base of the event occurred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andrea.bedei2\\AppData\\Local\\anaconda3\\envs\\carla-env\\lib\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning: Callback API version 1 is deprecated, update to latest version\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "BROKER = \"cd027bc56d0e4f84a8cd8c7558775d7b.s1.eu.hivemq.cloud\"\n",
    "PORT = 8883    \n",
    "\n",
    "clientMQTT = mqtt.Client()\n",
    "clientMQTT.username_pw_set(\"andrea\", \"Password123\")\n",
    "clientMQTT.tls_set(tls_version=mqtt.ssl.PROTOCOL_TLS)\n",
    "clientMQTT.connect(BROKER, PORT, 60)\n",
    "def sendEventToBroker(topic, message):\n",
    "    try:\n",
    "        clientMQTT.publish(topic, message)\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Client configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = carla.Client('localhost', 2000)\n",
    "client.set_timeout(10.0)\n",
    "client.load_world('Town02')\n",
    "world = client.get_world()\n",
    "spectator = world.get_spectator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions used in this notebook\n",
    "- **spawn_vehicle:** Adds a vehicle to the simulation.\n",
    "  - Picks a vehicle type from the blueprint library (pattern).\n",
    "  - Selects a spawn point on the map (spawn_index).\n",
    "  - Places the vehicle at that location.\n",
    "- **spawn_camera** Adds a camera to the simulation.\n",
    "  - Sets the camera size, field of view (foV), and update speed.\n",
    "  - Places the camera at a specific position and angle.\n",
    "  - Attaches the camera to a vehicle.\n",
    "- **IMAGE_SIZE** The dimension of the picture taken by the camera, except for the driver.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 640\n",
    "correct_map = False\n",
    "\n",
    "def spawn_vehicle(vehicle_index=0, spawn_index=0, pattern='vehicle.*'):\n",
    "    blueprint_library = world.get_blueprint_library()\n",
    "    vehicle_bp = blueprint_library.filter(pattern)[vehicle_index]\n",
    "    spawn_point = world.get_map().get_spawn_points()[spawn_index]\n",
    "    vehicle = world.spawn_actor(vehicle_bp, spawn_point)\n",
    "    return vehicle\n",
    "\n",
    "if world.get_map().name == \"Town02\" or world.get_map().name == \"Town01\":\n",
    "    correct_map = True\n",
    "\n",
    "def spawn_camera(attach_to=None, sensor_tick=0, transform=carla.Transform(carla.Location(x=1, z=1.8), carla.Rotation(pitch=5, yaw=35)), width=IMAGE_SIZE, height=IMAGE_SIZE, foV=50, exposure_mode='auto', expousure_compensation=0):\n",
    "    camera_bp = world.get_blueprint_library().find('sensor.camera.rgb')\n",
    "    camera_bp.set_attribute('image_size_x', str(width))\n",
    "    camera_bp.set_attribute('image_size_y', str(height))\n",
    "    camera_bp.set_attribute('fov', str(foV))\n",
    "    camera_bp.set_attribute('sensor_tick', str(sensor_tick))\n",
    "    camera_bp.set_attribute('exposure_mode', exposure_mode)\n",
    "    camera_bp.set_attribute('exposure_compensation', str(expousure_compensation))  \n",
    "    camera = world.spawn_actor(camera_bp, transform, attach_to=attach_to)\n",
    "    return camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training YOLOv8 Models for Object Detection\n",
    "\n",
    "### Overview\n",
    "We have trained the **YOLOv8** model multiple times to detect specific objects with two categories:\n",
    "\n",
    "1. **Speed Limits**:\n",
    "    - **First Training**: Using images of the speed limit signs without any background.\n",
    "    - **Second Training**: Using images of speed limit signs in real-world environments, with significant background clutter for object detection.\n",
    "\n",
    "2. **Traffic Lights**:\n",
    "    - **First Training**: Using images of the traffic lights without any background.\n",
    "    - **Second Training**: Using images of traffic lights in real-world environments, with significant background clutter for object detection.\n",
    "\n",
    "At the end, we will have **two YOLOv8 models**:\n",
    "- One dedicated to **speed limits**.\n",
    "- One dedicated to **traffic lights**.\n",
    "\n",
    "### Dataset\n",
    "The datasets used for training were sourced from the following site:  \n",
    "[Roboflow Universe](https://universe.roboflow.com/)\n",
    "\n",
    "### Base Code for Downloading and Training the Model\n",
    "Below is the base code to download the dataset and train the YOLOv8 model: (see training.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model Results\n",
    "<img src=\"runsSpeed/detect/train/confusion_matrix.png\" alt=\"Descrizione dell'immagine\" width=\"700\">\n",
    "<img src=\"runsFinLight/detect/train/confusion_matrix.png\" alt=\"Descrizione dell'immagine\" width=\"700\">\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pretrained Models\n",
    "\n",
    "We load the pretrained weights of yolo model in order to use them for the predictions with GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"runsSpeed/detect/train/weights/best.pt\")\n",
    "modelTrafficLight = YOLO(\"runsFinLight/detect/train/weights/best.pt\")\n",
    "modelTrafficLightOver = YOLO(\"runsUlt/detect/train7/weights/best.pt\")\n",
    "model.to(\"cuda:0\")\n",
    "modelTrafficLight.to(\"cuda:0\")\n",
    "modelTrafficLightOver.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set weather conditions\n",
    "- Set the worst weather condition or the best weather condition, to set night condition comment the second cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = world.get_weather()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.sun_azimuth_angle = 0\n",
    "weather.sun_altitude_angle = -90\n",
    "weather.cloudiness = 100\n",
    "weather.precipitation = 100\n",
    "weather.precipitation_deposits = 100\n",
    "weather.wind_intensity = 100\n",
    "weather.fog_density = 70\n",
    "weather.fog_distance = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.sun_azimuth_angle = 0 \n",
    "weather.sun_altitude_angle = 90\n",
    "weather.cloudiness = 20\n",
    "weather.precipitation = 0\n",
    "weather.precipitation_deposits = 0\n",
    "weather.wind_intensity = 0\n",
    "weather.fog_density = 30\n",
    "weather.fog_distance = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.set_weather(weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color utility functions\n",
    "- **colorSpeedLimit**: Change the letters color in the view.\n",
    "- **calcColor**: Change the letters color of the traffic light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorSpeedLimit(current_speed, speed_limit):\n",
    "    if speed_limit == None or int(current_speed) <= int(speed_limit):\n",
    "        return (0, 255, 0) \n",
    "    else:\n",
    "        return (0, 0, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcColor(traffic_light):\n",
    "    if traffic_light == \"red\":\n",
    "        return (0, 0, 255)\n",
    "    elif traffic_light == \"yellow\":\n",
    "        return (0, 255, 255)\n",
    "    elif traffic_light == \"green\":\n",
    "        return (0, 255, 0)\n",
    "    else:\n",
    "        return (255, 255, 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sign_camera_callback\n",
    "\n",
    "This function processes an image captured by a camera, analyzes it using our machine learning model (Yolo), and identifies the most likely speed limit sign if detected with high confidence. The results are then sent to an external system.\n",
    "\n",
    "### Key Steps:\n",
    "\n",
    "1. **Global Variable:**\n",
    "   - **`last_speed_limit`:** Stores the last detected speed limit value to avoid redundant notifications.\n",
    "\n",
    "2. **Image Data Conversion:**\n",
    "   - Converts the raw image data from the simulator to a NumPy array using `np.frombuffer`.\n",
    "   - Reshapes the data into its original dimensions, including an alpha channel (RGBA format).\n",
    "   - Removes the alpha channel to work with the RGB image (`image_bgr`).\n",
    "\n",
    "3. **Model Prediction:**\n",
    "   - Passes the RGB image (`image_bgr`) to YOLO for analysis.\n",
    "   - Extracts the detected class IDs (`class_ids`) and their corresponding confidence scores (`confidences`) from the model’s results.\n",
    "\n",
    "4. **Identify the Most Likely Speed Limit:**\n",
    "   - Iterates through detected objects, keeping track of the class ID with the highest confidence score.\n",
    "   - If the highest confidence exceeds a threshold (`0.87`), identifies the corresponding class name from the `class_names` list.\n",
    "\n",
    "5. **Extract and Notify Speed Limit:**\n",
    "   - Attempts to extract the speed limit value from the class name using string splitting (`class_name.split(\" \")[2]`).\n",
    "   - If the detected speed limit is new or different from the previous one, sends an event to an external broker using `sendEventToBroker`.\n",
    "   - Updates `last_speed_limit` with the detected value.\n",
    "\n",
    "### Notes:\n",
    "- The function ensures that only high-confidence detections are processed to reduce false positives.\n",
    "- It avoids redundant notifications by checking if the new detection differs from the last one.\n",
    "- Any errors during the string extraction or event sending are silently handled.\n",
    "\n",
    "This callback is integral to detecting and responding to traffic signs in real-time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traffic_sign_camera_callback(image, class_names):\n",
    "    global last_speed_limit\n",
    "\n",
    "    array = np.frombuffer(image.raw_data, dtype=np.uint8)\n",
    "    image_np = array.reshape((IMAGE_SIZE, IMAGE_SIZE, 4))\n",
    "    image_bgr = image_np[:, :, :3]\n",
    "\n",
    "    results = model(image_bgr, verbose=False)\n",
    "    limit_id = None\n",
    "    confidence_max = 0\n",
    "    class_ids = results[0].boxes.cls.cpu().numpy()\n",
    "    confidences = results[0].boxes.conf.cpu().numpy()\n",
    "    \n",
    "    for class_id, confidence in zip(class_ids, confidences):\n",
    "        if confidence > confidence_max:\n",
    "            limit_id = class_id\n",
    "            confidence_max = confidence\n",
    "\n",
    "    if confidence_max > 0.87:\n",
    "        class_name = class_names[int(limit_id)]\n",
    "        try:\n",
    "            if last_speed_limit == None or last_speed_limit != class_name.split(\" \")[2]:\n",
    "                sendEventToBroker(\"speedLimit\", \"Detected \" + class_name.split(\" \")[2])\n",
    "            last_speed_limit = class_name.split(\" \")[2]\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View_camera_callback:\n",
    "\n",
    "This function processes an image captured by the camera dedicated to the driver and updates the global variables used for video output.\n",
    "\n",
    "1. **Global Variables:**\n",
    "   - `video_output`: A global variable used to store the processed image data for visualization or further use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_camera_callback(image):\n",
    "    global video_output\n",
    "    array = np.frombuffer(image.raw_data, dtype=np.uint8)\n",
    "    image_np = array.reshape((height_screen, width_screen, 4))\n",
    "    video_output = image_np[:, :, :3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera_trafficlight_callback:\n",
    "\n",
    "This function processes an image from a camera to detect the current state of a traffic light. It enhances the image, analyzes it with YOLO, updates global variables, and sends notifications to the MQTT broker when the state changes.\n",
    "\n",
    "### Key Steps:\n",
    "\n",
    "1. **Global Variable:**\n",
    "   - **`traffic_light`:** Stores the detected traffic light state (`\"red\"`, `\"yellow\"`, `\"green\"`, or `\"Not detected\"`).\n",
    "\n",
    "2. **Image Data Conversion:**\n",
    "   - Converts the raw image data from the camera into a NumPy array using `np.frombuffer`.\n",
    "   - Reshapes the array into an image matrix of size `IMAGE_SIZE x IMAGE_SIZE` with 4 channels (BGRA format).\n",
    "   - Extracts the RGB portion (`image_bgr`) for further processing.\n",
    "\n",
    "3. **Traffic Light Detection:**\n",
    "   - Passes the processed image (`resized_image`) to the traffic light detection model (YOLO).\n",
    "   - Retrieves the detected class IDs (`class_ids`) and their confidence scores (`confidences`).\n",
    "   - If no traffic lights are detected, sets `traffic_light` to `\"Not detected\"`.\n",
    "\n",
    "4. **Identify the Most Likely Traffic Light State:**\n",
    "   - Iterates through the detected objects, identifying the class ID with the highest confidence score.\n",
    "   - Determines the traffic light state (`\"red\"`, `\"yellow\"`, or `\"green\"`) based on the class name.\n",
    "   - Applies confidence thresholds to reduce false positives:\n",
    "     - **High confidence (`>0.55`)** for `\"red\"` and `\"green\"`.\n",
    "     - **Moderate confidence (`>0.45`)** for `\"yellow\"`.\n",
    "\n",
    "5. **State Update and Notification:**\n",
    "   - If the detected traffic light state differs from the previous state stored in `traffic_light`, updates `traffic_light`.\n",
    "   - Sends a notification to the MQTT broker using `sendEventToBroker` with the new traffic light state.\n",
    "\n",
    "### Notes:\n",
    "- The function ensures that only high-confidence detections trigger updates.\n",
    "- It differentiates between colors with specific thresholds to improve accuracy.\n",
    "- Any significant state changes are notified to MQTT broker.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camera_trafficlight_callback(image, class_names_trafficLight):\n",
    "    global traffic_light\n",
    "    array = np.frombuffer(image.raw_data, dtype=np.uint8)\n",
    "    image_np = array.reshape((IMAGE_SIZE, IMAGE_SIZE, 4))\n",
    "    image_bgr = image_np[:, :, :3].copy()\n",
    "    resized_image = image_bgr.copy()\n",
    "\n",
    "    results = modelTrafficLight(resized_image, verbose=False)\n",
    "    trafficLight_id = None\n",
    "    confidence_max = 0\n",
    "    class_ids = results[0].boxes.cls.cpu().numpy()\n",
    "    confidences = results[0].boxes.conf.cpu().numpy()\n",
    "\n",
    "    if class_ids.size == 0:\n",
    "        traffic_light = \"Not detected\"\n",
    "    else:\n",
    "        for class_id, confidence in zip(class_ids, confidences):\n",
    "            if confidence > confidence_max:\n",
    "                trafficLight_id = class_id\n",
    "                confidence_max = confidence\n",
    "\n",
    "        if traffic_light != None and class_names_trafficLight[int(trafficLight_id)] == \"yellow\" and traffic_light == \"red\":\n",
    "            class_name = \"red\"\n",
    "        else:\n",
    "            class_name = class_names_trafficLight[int(trafficLight_id)]\n",
    "\n",
    "        if confidence_max > 0.55 and class_name==\"red\" or confidence_max > 0.55 and class_name==\"green\" or confidence_max > 0.45 and class_name==\"yellow\":\n",
    "            if traffic_light != class_name:\n",
    "                traffic_light = class_name\n",
    "                sendEventToBroker(\"TrafficLight\", \"Detected trafficlight \" + class_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red_over_camera_callback:\n",
    "\n",
    "This function operates similarly to `red_over_camera_callback(image)` but focuses specifically on detecting and reacting to **red traffic lights**, modifying a global flag (`red_over`) based on the detection results:\n",
    "\n",
    "1. **Global Variables:**\n",
    "   - `last_analysis_time_trafficLight_red`: Tracks the time of the last analysis for red traffic lights to ensure periodic updates.\n",
    "   - `red_over`: A flag indicating whether a red light condition has been detected and action of stopping should be enforced.\n",
    "\n",
    "2. **Traffic Light Detection:**\n",
    "   - Passes the processed image to the `modelTrafficLight`, which detects traffic light states and outputs class IDs (`class_ids`) and their confidence scores (`confidences`).\n",
    "   - Handles cases where no traffic lights are detected by resetting `red_over` to `False`.\n",
    "\n",
    "3. **Red Light Detection Logic:**\n",
    "   - Iterates through detected objects, identifying the class ID with the highest confidence score.\n",
    "   - If the detected class is `\"red\"` and the confidence score exceeds `0.65`: Sets `red_over` to `True` **unless the vehicle is in reverse (`gear != \"Reverse\"`)** or another condition prevents it.\n",
    "   - If the detected class is `\"green\"` or `\"yellow\"` and the confidence score exceeds `0.43`: Resets `red_over` to `False`, allowing movement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def red_over_camera_callback(image, class_names_trafficLight):\n",
    "    global red_over, video_output2\n",
    "    array = np.frombuffer(image.raw_data, dtype=np.uint8)\n",
    "    image_np = array.reshape((IMAGE_SIZE, IMAGE_SIZE, 4))\n",
    "    image_bgr = image_np[:, :, :3].copy()\n",
    "    resized_image = image_bgr.copy()\n",
    "    video_output2 = resized_image\n",
    "\n",
    "    results = modelTrafficLightOver(resized_image, verbose=False)\n",
    "\n",
    "    trafficLight_id = None\n",
    "    confidence_max = 0\n",
    "\n",
    "    class_ids = results[0].boxes.cls.cpu().numpy()\n",
    "    confidences = results[0].boxes.conf.cpu().numpy()\n",
    "\n",
    "    if class_ids.size != 0:\n",
    "        for class_id, confidence in zip(class_ids, confidences):\n",
    "            if confidence > confidence_max:\n",
    "                trafficLight_id = class_id\n",
    "                confidence_max = confidence\n",
    "\n",
    "        class_name = class_names_trafficLight[int(trafficLight_id)]\n",
    "        if class_name==\"red\" and confidence_max > 0.489:\n",
    "            if(gear != \"Reverse\" and not red_over): # type: ignore\n",
    "                red_over = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hazard Lights Control\n",
    "These functions manage the activation and deactivation of hazard lights after a red over. Hazard lights indicate an emergency or warning scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activate_hazard_lights(vehicle):\n",
    "    global hazard_lights_active, hazard_lights_start_time\n",
    "    hazard_lights_active = True\n",
    "    hazard_lights_start_time = time.time()\n",
    "    vehicle.set_light_state(carla.VehicleLightState(carla.VehicleLightState.RightBlinker | carla.VehicleLightState.LeftBlinker))\n",
    "\n",
    "def deactivate_hazard_lights(vehicle):\n",
    "    global hazard_lights_active\n",
    "    hazard_lights_active = False\n",
    "    vehicle.set_light_state(carla.VehicleLightState.NONE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PrintTextOnScreen\n",
    "Utility function to print words on the screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_text_on_screen(temp_frame, text, position, color):\n",
    "    cv2.putText(\n",
    "        temp_frame,\n",
    "        text,\n",
    "        position,\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        1,\n",
    "        color,\n",
    "        4,\n",
    "        cv2.LINE_AA,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check_red_over:\n",
    "This function checks if the red over was already actuated, in this case it won't do anything otherwise it will  send the message to the MQTT broker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_red_over(text_red_val):\n",
    "    if red_over:\n",
    "        if text_red_val != \"You ran a red light\":\n",
    "            sendEventToBroker(\"TrafficLightViolation\", \"Red light violation\")\n",
    "        return \"You ran a red light\"\n",
    "    else:\n",
    "        return \"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## init_joystick:\n",
    "This function initializes the joystick, configures the controls for a racing wheel (G29), and stores joystick input values for later use in controlling the vehicle.\n",
    "1. **Joystick Setup:**\n",
    "   - Initializes the first joystick (`Joystick(0)`) and sets it up for use.\n",
    "   - Reads the configuration file `wheel_config.ini` to retrieve control mappings for various inputs.\n",
    "\n",
    "2. **Control Mappings:**\n",
    "   - Parses the configuration file to obtain the indices for the following controls:\n",
    "     - **`steer_idx`:** Steering wheel control index.\n",
    "     - **`throttle_idx`:** Throttle control index.\n",
    "     - **`brake_idx`:** Brake control index.\n",
    "     - **`reverse_idx`:** Reverse control index.\n",
    "     - **`handbrake_idx`:** Handbrake control index.\n",
    "\n",
    "3. **Joystick Inputs:**\n",
    "   - Retrieves the number of axes on the joystick (`numAxes`).\n",
    "   - Creates a list of joystick inputs (`jsInputs`), storing the current values for each axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_joistick():\n",
    "    global joystick, joystick_count, parser, steer_idx, throttle_idx, brake_idx, reverse_idx, handbrake_idx, numAxes, jsInputs\n",
    "    pygame.joystick.init()\n",
    "    joystick_count = pygame.joystick.get_count()\n",
    "    if joystick_count > 1:\n",
    "        raise ValueError(\"Please Connect Just One Joystick\")\n",
    "\n",
    "    joystick = pygame.joystick.Joystick(0)\n",
    "    joystick.init()\n",
    "\n",
    "    parser = ConfigParser()\n",
    "\n",
    "    parser.read('.\\wheel_config.ini')\n",
    "    steer_idx = int(\n",
    "    parser.get('G29 Racing Wheel', 'steering_wheel'))\n",
    "    throttle_idx = int(\n",
    "    parser.get('G29 Racing Wheel', 'throttle'))\n",
    "    brake_idx = int(parser.get('G29 Racing Wheel', 'brake'))\n",
    "    reverse_idx = int(parser.get('G29 Racing Wheel', 'reverse'))\n",
    "    handbrake_idx = int(\n",
    "    parser.get('G29 Racing Wheel', 'handbrake'))\n",
    "\n",
    "    numAxes = joystick.get_numaxes()\n",
    "    jsInputs = [float(joystick.get_axis(i)) for i in range(numAxes)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Control Loop for CARLA\n",
    "\n",
    "This section of the code sets up the environment, initializes variables, and runs the main control loop for manual control of a CARLA simulation vehicle. The loop handles vehicle control based on joystick or keyboard inputs, processes events, and manages the vehicle's state, such as gear, speed, and hazard light status.\n",
    "\n",
    "### Steps:\n",
    "\n",
    "1. **Pygame Window Setup:**\n",
    "   - Creates a Pygame window.\n",
    "   - Calls `init_joistick()` to initialize the joystick for controlling the vehicle.\n",
    "\n",
    "2. **Control Variables:**\n",
    "   - Defines incremental values for steering and throttle adjustments (`steer_increment`, `throttle_increment`).\n",
    "   - Sets the initial values for vehicle controls such as `steer`, `throttle`, `brake`, and `gear`.\n",
    "   - Initialization of: flags for speed control, autopilot activation, red light detection, and other features.\n",
    "\n",
    "3. **Proportional Controller Constants:**\n",
    "   - Defines constants for controlling throttle (`KP_THROTTLE`), brake (`KP_BRAKE`), and dead zone (`DEAD_ZONE`), alongside minimum values for throttle and brake.\n",
    "\n",
    "4. **Video Frame Initialization:**\n",
    "   - Initializes a `video_output` array to store video frames captured by the vehicle's camera.\n",
    "\n",
    "5. **Speed and Traffic Light Tracking:**\n",
    "   - Initializes variables to track the vehicle's speed (`car_speed`) and traffic light state (`traffic_light`).\n",
    "\n",
    "6. **Model Class Names:**\n",
    "   - Loads class names for object detection models (`model.names` for object detection and `modelTrafficLight.names` for traffic light detection).\n",
    "\n",
    "7. **Vehicle and Camera Setup:**\n",
    "   - Spawns a vehicle (`vehicle`) and attaches cameras for different purposes, such as speed limit detection and traffic light detection.\n",
    "   - Configures cameras with specific parameters (e.g., resolution, field of view) and attaches callbacks to handle image processing.\n",
    "\n",
    "8. **Event Loop:**\n",
    "    - Runs the main loop, handling joystick, keyboard, and game events. The loop:\n",
    "      - Retrieves and processes vehicle velocity.\n",
    "      - Displays various vehicle status overlays on the screen (e.g., current speed, gear, traffic light state).\n",
    "      - Handles user inputs (e.g., speed control, autopilot toggle, red light detection) via keyboard and joystick buttons.\n",
    "      - Applies proportional control to adjust throttle and brake based on speed limits.\n",
    "      - Activates hazard lights and brakes if the red light detection feature is triggered.\n",
    "\n",
    "9. **Control Application:**\n",
    "    - At each frame, the vehicle's control (throttle, brake, steer, reverse) is updated based on input values.\n",
    "    - If hazard lights are active for more than 2 seconds, they are deactivated.\n",
    "\n",
    "10. **Clean Up:**\n",
    "    - Finally, ensures proper cleanup of resources, including destroying windows, disconnecting the MQTT client, and removing the vehicle and camera objects.\n",
    "\n",
    "### Event Handling:\n",
    "- **Joystick and Keyboard Inputs:** The loop checks for joystick button presses and keyboard key events to toggle features like speed control, autopilot, red light detection, and gear changes.\n",
    "- **Throttle and Brake Control:** Speed control logic adjusts throttle and brake values based on the current speed and speed limits.\n",
    "- **Steering Control:** Steering is controlled using joystick input or keyboard keys (A/D for left/right)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displayCommand = pygame.display.set_mode((200, 100))\n",
    "pygame.display.set_caption(\"Manual Control CARLA\")\n",
    "init_joistick()\n",
    "\n",
    "hazard_lights_active = False\n",
    "hazard_lights_start_time = 0\n",
    "\n",
    "# Define control variables and increments\n",
    "steer_increment = 0.02  # Increment for steering adjustments\n",
    "throttle_increment = 0.1  # Increment for throttle adjustments\n",
    "steer = 0.0  # Current steering value\n",
    "throttle = 0.0  # Current throttle value\n",
    "brake = 0.0  # Current brake value\n",
    "global gear  # Define a global gear variable\n",
    "gear = \"Drive\"  # Initial gear state\n",
    "speed_control_activate = False  # Flag for speed control activation\n",
    "auto_pilot_activate = False  # Flag for autopilot activation\n",
    "red_over_activate = False  # Flag for red light detection activation\n",
    "red_over = False  # Red light violation flag\n",
    "global control # Set the car control\n",
    "text_red_val = \"\"\n",
    "\n",
    "# Constants for proportional controller\n",
    "KP_THROTTLE = 0.15  # Proportional gain for acceleration\n",
    "KP_BRAKE = 0.02  # Proportional gain for braking\n",
    "DEAD_ZONE = 3.0  # Dead zone around the speed limit\n",
    "MIN_THROTTLE = 0.2  # Minimum throttle value\n",
    "MIN_BRAKE = 0.1  # Minimum brake value\n",
    "\n",
    "# Initialize the output video frame\n",
    "video_output = np.zeros((width_screen, height_screen, 3), dtype=np.uint8)\n",
    "\n",
    "# Variables for speed and traffic light tracking\n",
    "last_speed_limit = None  # Last detected speed limit\n",
    "car_speed = 0  # Current vehicle speed\n",
    "traffic_light = \"Not detected\"  # Current traffic light state\n",
    "\n",
    "# Load class names for object detection models\n",
    "class_names = model.names  # Object detection model names\n",
    "class_names_trafficLight = modelTrafficLight.names  # Traffic light model names\n",
    "\n",
    "# Spawn the simulated vehicle\n",
    "vehicle = spawn_vehicle()\n",
    "\n",
    "# Checks the sun altitude and if it is dark turns on the lights\n",
    "sun_altitude = weather.sun_altitude_angle\n",
    "if sun_altitude < 10:\n",
    "    vehicle.set_light_state(carla.VehicleLightState.HighBeam)\n",
    "else: \n",
    "    vehicle.set_light_state(carla.VehicleLightState.NONE)\n",
    "\n",
    "\n",
    "# Attach and configure cameras for various purposes\n",
    "speed_limit_camera = spawn_camera(attach_to=vehicle, sensor_tick=0.2) # Camera focused on speedlimit\n",
    "speed_limit_camera.listen(lambda image: traffic_sign_camera_callback(image, class_names))\n",
    "\n",
    "camera_view = spawn_camera(\n",
    "    attach_to=vehicle, \n",
    "    sensor_tick=0.0,\n",
    "    transform=carla.Transform(carla.Location(x=1, z=1.5), carla.Rotation(pitch=0, yaw=0)), \n",
    "    width=width_screen, \n",
    "    height=height_screen, \n",
    "    foV=115\n",
    ")  # Driver's perspective camera\n",
    "camera_view.listen(lambda image: view_camera_callback(image))\n",
    "\n",
    "if correct_map:\n",
    "    trafficLight_camera = spawn_camera(\n",
    "        attach_to=vehicle, \n",
    "        sensor_tick=0.25,\n",
    "        transform=carla.Transform(carla.Location(x=0.3, y=1, z=1.2), carla.Rotation(pitch=10, yaw=5)), \n",
    "        width=IMAGE_SIZE, \n",
    "        height=IMAGE_SIZE, \n",
    "        foV=35,\n",
    "    ) # Camera focused on trafficlight\n",
    "    trafficLight_camera.listen(lambda image: camera_trafficlight_callback(image, class_names_trafficLight))\n",
    "    \n",
    "    trafficLight_red_camera = spawn_camera(\n",
    "        attach_to=vehicle,\n",
    "        sensor_tick=0.10,\n",
    "        transform=carla.Transform(carla.Location(x=-1, y=0, z=2), carla.Rotation(pitch=-5, yaw=5)), \n",
    "        width=IMAGE_SIZE, \n",
    "        height=IMAGE_SIZE, \n",
    "        foV=120\n",
    "    ) # Camera focused on red over\n",
    "    trafficLight_red_camera.listen(lambda image: red_over_camera_callback(image, class_names_trafficLight))\n",
    "\n",
    "# Create an OpenCV window for displaying results\n",
    "cv2.namedWindow('RGB Camera', cv2.WINDOW_FULLSCREEN)\n",
    "\n",
    "try:\n",
    "    clock = pygame.time.Clock()  # Pygame clock for controlling loop rate\n",
    "    event_timer = 0  # Timer for event processing\n",
    "    EVENT_RATE = 100  # Event handling interval in milliseconds\n",
    "\n",
    "    while True:\n",
    "        time_hazard = time.time()\n",
    "        jsInputs = [float(joystick.get_axis(i)) for i in range(numAxes)]\n",
    "\n",
    "        # Get the car velocity.\n",
    "        car_velocity = vehicle.get_velocity()\n",
    "        car_speed = 3.6 * (car_velocity.x**2 + car_velocity.y**2 + car_velocity.z**2)**0.5\n",
    "\n",
    "        # Add text overlays to the output frame\n",
    "        temp_frame = video_output.copy()\n",
    "        print_text_on_screen(temp_frame, f\"Last Speed Limit: {last_speed_limit}\", (10, 30), (0, 255, 0))\n",
    "        print_text_on_screen(temp_frame, f\"Current speed: {car_speed:.0f}\", (10, 70), colorSpeedLimit(car_speed, last_speed_limit))\n",
    "        print_text_on_screen(temp_frame,  f\"Traffic light: {traffic_light}\", (10, 110), calcColor(traffic_light))\n",
    "        print_text_on_screen(temp_frame, f\"(LT RT) Gear: {gear}\", (10, 150), (255, 255, 255))\n",
    "        print_text_on_screen(temp_frame,  f\"B Autopilot: {auto_pilot_activate}\", (10, 190), (255, 255, 255))\n",
    "        print_text_on_screen(temp_frame, f\"X SpeedControl: {speed_control_activate}\", (10, 230), (255, 255, 255))\n",
    "        print_text_on_screen(temp_frame,  f\"Y Red Over Automatic Brake: {red_over_activate}\", (10, 270), (255, 255, 255))\n",
    "        # If the speed is 0, red over is turned off.\n",
    "        if car_speed<=1:\n",
    "            red_over = False\n",
    "        text_red_val = check_red_over(text_red_val)\n",
    "        print_text_on_screen(temp_frame,  text_red_val, (10, 310), (0, 0, 255))\n",
    "\n",
    "        # Show the frame with overlays\n",
    "        cv2.imshow('RGB Camera', temp_frame)\n",
    "\n",
    "        # Break the loop on 'q' key press\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "\n",
    "        # Handle Pygame events periodically\n",
    "        current_time = pygame.time.get_ticks()\n",
    "        if current_time - event_timer > EVENT_RATE:\n",
    "            event_timer = current_time\n",
    "            for event in pygame.event.get():\n",
    "                if event.type == pygame.QUIT:\n",
    "                    break\n",
    "                elif event.type == pygame.KEYUP:  # Handle key releases\n",
    "                    if event.key == pygame.K_x:  # Toggle speed control\n",
    "                        speed_control_activate = not speed_control_activate\n",
    "                    if event.key == pygame.K_b:  # Enable autopilot\n",
    "                        auto_pilot_activate = not auto_pilot_activate\n",
    "                        vehicle.set_autopilot(auto_pilot_activate)\n",
    "                    if event.key == pygame.K_y:  # Toggle red light detection\n",
    "                        red_over_activate = not red_over_activate\n",
    "                    if event.key == pygame.K_r:  # Reverse gear\n",
    "                        gear = \"Reverse\"\n",
    "                        red_over = False\n",
    "                    elif event.key == pygame.K_l:  # Forward gear\n",
    "                        gear = \"Drive\"\n",
    "                elif event.type == pygame.JOYBUTTONDOWN:\n",
    "                    if event.button == 1: # Toggle speed control\n",
    "                        speed_control_activate = not speed_control_activate\n",
    "                    elif event.button == 2: # Enable autopilot\n",
    "                        auto_pilot_activate = not auto_pilot_activate\n",
    "                        vehicle.set_autopilot(auto_pilot_activate)\n",
    "                    elif event.button == 3: # Toggle red light detection\n",
    "                        red_over_activate = not red_over_activate\n",
    "                    elif event.button == 6: # Reverse gear\n",
    "                        gear = \"Reverse\"\n",
    "                        red_over = False\n",
    "                    elif event.button == 7: # Forward gear\n",
    "                        gear = \"Drive\"\n",
    "\n",
    "\n",
    "            keys = pygame.key.get_pressed()  # Get pressed keys\n",
    "\n",
    "            K2 = 1.6\n",
    "            # Fix bugs, at the beginning js returns only 0.0 value\n",
    "            if jsInputs[throttle_idx] == 0.0:\n",
    "                throttleCmd = 0\n",
    "            else:\n",
    "                throttleCmd =  K2 + (2.05 * math.log10(0.7 * jsInputs[throttle_idx] + 1.4) - 1.2) / 0.92\n",
    "                if throttleCmd <= 0:\n",
    "                    throttleCmd = 0\n",
    "                elif throttleCmd > 1:\n",
    "                    throttleCmd = 1\n",
    "\n",
    "            # Handle speed control logic and throttle\n",
    "            if speed_control_activate and last_speed_limit and (jsInputs[throttle_idx]>-0.95 or jsInputs[throttle_idx]>0.0):\n",
    "                # Calculate speed error relative to the limit\n",
    "                error = float(last_speed_limit) - float(car_speed) + 3\n",
    "                if error < -DEAD_ZONE:\n",
    "                    throttle = 0\n",
    "                    brake = max(KP_BRAKE * abs(error), MIN_BRAKE)\n",
    "                else:\n",
    "                    throttle = min(max(KP_THROTTLE * error, MIN_THROTTLE), throttleCmd)\n",
    "                    brake = 0\n",
    "            elif speed_control_activate and last_speed_limit and keys[pygame.K_w]:\n",
    "                # Calculate speed error relative to the limit\n",
    "                error = float(last_speed_limit) - float(car_speed) + 3\n",
    "                if error < -DEAD_ZONE:\n",
    "                    throttle = 0\n",
    "                    brake = max(KP_BRAKE * abs(error), MIN_BRAKE)\n",
    "                else:\n",
    "                    throttle = max(KP_THROTTLE * error, MIN_THROTTLE)\n",
    "                    brake = 0\n",
    "            elif keys[pygame.K_w]:  # Manual throttle control\n",
    "                throttle = min(throttle + throttle_increment, 1)\n",
    "                brake = 0\n",
    "            elif throttleCmd>-0.95:\n",
    "                throttle = throttleCmd\n",
    "                brake=0\n",
    "            else:\n",
    "                throttle = 0\n",
    "                brake = 0\n",
    "\n",
    "            # Handle brake logic\n",
    "            brakeCmd = 1.6 + (2.05 * math.log10(0.7 * jsInputs[brake_idx] + 1.4) - 1.2) / 0.92\n",
    "            if brakeCmd <= 0:\n",
    "                brakeCmd = 0\n",
    "            elif brakeCmd > 1:\n",
    "                brakeCmd = 1\n",
    "            \n",
    "            if brakeCmd>0.1:\n",
    "                brake = brakeCmd\n",
    "                throttle = 0\n",
    "            elif keys[pygame.K_s]:  # Manual brake control\n",
    "                brake = min(brake + throttle_increment * 4, 1)\n",
    "                throttle = 0\n",
    "\n",
    "            # Check it the brake will be activated due to a red over.\n",
    "            if red_over and int(car_speed) <= 50 and gear != \"Reverse\" and red_over_activate:\n",
    "                activate_hazard_lights(vehicle)\n",
    "                brake = 1\n",
    "                throttle = 0\n",
    "            \n",
    "            # Turn off the red over if it is not activate.\n",
    "            if not red_over_activate:\n",
    "                red_over = False\n",
    "            \n",
    "\n",
    "            # Handle steering controls\n",
    "            if keys[pygame.K_a]:  # Steer left\n",
    "                steer = max(steer - steer_increment, -1)\n",
    "            elif keys[pygame.K_d]:  # Steer right\n",
    "                steer = min(steer + steer_increment, 1)\n",
    "            else:\n",
    "                if joystick_count == 1:\n",
    "                    K1 = 1.0  \n",
    "                    steer = K1 * math.tan(1.1 * jsInputs[steer_idx])\n",
    "                else:\n",
    "                    steer = steer * 0.9  # Gradually return to center\n",
    "\n",
    "            if hazard_lights_active and (time_hazard - hazard_lights_start_time > 2):\n",
    "                deactivate_hazard_lights(vehicle)\n",
    "\n",
    "            control = carla.VehicleControl()\n",
    "            control.throttle = throttle\n",
    "            control.brake = brake\n",
    "            control.steer = steer\n",
    "            control.reverse = (gear == \"Reverse\")\n",
    "            vehicle.apply_control(control)\n",
    "\n",
    "        clock.tick(40)  # Maintain a 40 FPS loop rate\n",
    "finally:\n",
    "    # Clean up resources and connections\n",
    "    cv2.destroyAllWindows()\n",
    "    pygame.quit()\n",
    "    speed_limit_camera.destroy()\n",
    "    trafficLight_camera.destroy()\n",
    "    trafficLight_red_camera.destroy()\n",
    "    camera_view.destroy()\n",
    "    vehicle.destroy()\n",
    "    clientMQTT.disconnect()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carla-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

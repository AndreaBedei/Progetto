{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carla speed limit assist with corrective actions and traffic light detection and warning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import library\n",
    "- **cv2 (OpenCV):** computer vision library for image processing. Used for handling and processing video frames or images.\n",
    "- **paho.mqtt.client:** client library for the MQTT protocol, this library permit to publish MQTT topics, likely for exchanging data between the CARLA simulator and other systems.\n",
    "- **ultralytics (YOLO):** provides Python interface for the YOLO (You Only Look Once) object detection framework. It provide object detection tasks, such as identify traffic light, speedLimit.\n",
    "- **pygame:** library for creating games and multimedia applications, it allows to take input events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import paho.mqtt.client as mqtt\n",
    "from ultralytics import YOLO\n",
    "from screeninfo import get_monitors\n",
    "from manual_control_steeringwheel import DualControl\n",
    "import time\n",
    "import pygame\n",
    "\n",
    "try:\n",
    "    sys.path.append(glob.glob('../../carla/dist/carla-*%d.%d-%s.egg' % (\n",
    "        sys.version_info.major,\n",
    "        sys.version_info.minor,\n",
    "        'win-amd64' if os.name == 'nt' else 'linux-x86_64'))[0])\n",
    "except IndexError:\n",
    "    pass\n",
    "\n",
    "import carla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "width_screen = 0\n",
    "height_screen = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larghezza dello schermo più grande: 5120\n",
      "Altezza dello schermo più grande: 1440\n"
     ]
    }
   ],
   "source": [
    "width_screen = 0\n",
    "height_screen = 0\n",
    "\n",
    "def get_screen_dimensions():\n",
    "    global width_screen, height_screen  # Dichiarazione esplicita\n",
    "    monitors = get_monitors()\n",
    "    for monitor in monitors:\n",
    "        if width_screen < monitor.width:  # Confronta la larghezza per trovare il monitor più grande\n",
    "            width_screen = monitor.width\n",
    "            height_screen = monitor.height\n",
    "\n",
    "get_screen_dimensions()\n",
    "print(f\"Larghezza dello schermo più grande: {width_screen}\")\n",
    "print(f\"Altezza dello schermo più grande: {height_screen}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broker MQTT configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andrea.bedei2\\AppData\\Local\\anaconda3\\envs\\carla-env\\lib\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning: Callback API version 1 is deprecated, update to latest version\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "BROKER = \"cd027bc56d0e4f84a8cd8c7558775d7b.s1.eu.hivemq.cloud\"\n",
    "PORT = 8883    \n",
    "\n",
    "clientMQTT = mqtt.Client()\n",
    "clientMQTT.username_pw_set(\"andrea\", \"Password123\")\n",
    "clientMQTT.tls_set(tls_version=mqtt.ssl.PROTOCOL_TLS)\n",
    "clientMQTT.connect(BROKER, PORT, 60)\n",
    "def sendEventToBroker(topic, message):\n",
    "    try:\n",
    "        clientMQTT.publish(topic, message)\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Client configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = carla.Client('localhost', 2000)\n",
    "client.set_timeout(10.0)\n",
    "client.load_world('Town02')\n",
    "world = client.get_world()\n",
    "spectator = world.get_spectator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpful functions used in this notebook\n",
    "- **spawn_vehicle:** Adds a vehicle to the simulation.\n",
    "  - Picks a vehicle type from the blueprint library (pattern).\n",
    "  - Selects a spawn point on the map (spawn_index).\n",
    "  - Places the vehicle at that location.\n",
    "- **spawn_camera** Adds a camera to the simulation.\n",
    "  - Sets the camera size, field of view (foV), and update speed.\n",
    "  - Places the camera at a specific position and angle.\n",
    "  - Attaches the camera to a vehicle.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "IMAGE_SIZE = 640\n",
    "currect_map = False\n",
    "\n",
    "def spawn_vehicle(vehicle_index=0, spawn_index=5, pattern='vehicle.*'):\n",
    "    blueprint_library = world.get_blueprint_library()\n",
    "    vehicle_bp = blueprint_library.filter(pattern)[vehicle_index]\n",
    "    spawn_point = world.get_map().get_spawn_points()[spawn_index]\n",
    "    vehicle = world.spawn_actor(vehicle_bp, spawn_point)\n",
    "    return vehicle\n",
    "\n",
    "if world.get_map().name == \"Town02\" or world.get_map().name == \"Town01\":\n",
    "    currect_map = True\n",
    "\n",
    "def spawn_camera(attach_to=None, sensor_tick=0, transform=carla.Transform(carla.Location(x=1, z=1.8), carla.Rotation(pitch=5, yaw=35)), width=IMAGE_SIZE, height=IMAGE_SIZE, foV=50, exposure_mode='auto', expousure_compensation=0):\n",
    "    camera_bp = world.get_blueprint_library().find('sensor.camera.rgb')\n",
    "    camera_bp.set_attribute('image_size_x', str(width))\n",
    "    camera_bp.set_attribute('image_size_y', str(height))\n",
    "    camera_bp.set_attribute('fov', str(foV))\n",
    "    camera_bp.set_attribute('sensor_tick', str(sensor_tick))\n",
    "    #camera_bp.set_attribute('bloom_intensity', \"0\")\n",
    "    camera_bp.set_attribute('exposure_mode', exposure_mode)\n",
    "    camera_bp.set_attribute('exposure_compensation', str(expousure_compensation))  # Riduce la luminosità\n",
    "    camera = world.spawn_actor(camera_bp, transform, attach_to=attach_to)\n",
    "    return camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training YOLOv8 Models for Object Detection\n",
    "\n",
    "### Overview\n",
    "We have trained the **YOLOv8** model multiple times to detect specific objects with two categories:\n",
    "\n",
    "1. **Speed Limits**:\n",
    "    - **First Training**: Using images of the speed limit signs without any background.\n",
    "    - **Second Training**: Using images of speed limit signs in real-world environments, with significant background clutter for object detection.\n",
    "\n",
    "2. **Traffic Lights**:\n",
    "    - **First Training**: Using images of the traffic lights without any background.\n",
    "    - **Second Training**: Using images of traffic lights in real-world environments, with significant background clutter for object detection.\n",
    "\n",
    "At the end, we will have **two YOLOv8 models**:\n",
    "- One dedicated to **speed limits**.\n",
    "- One dedicated to **traffic lights**.\n",
    "\n",
    "### Dataset\n",
    "The datasets used for training were sourced from the following site:  \n",
    "[Roboflow Universe](https://universe.roboflow.com/)\n",
    "\n",
    "### Base Code for Downloading and Training the Model\n",
    "Below is the base code to download the dataset and train the YOLOv8 model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install roboflow\n",
    "# from roboflow import Roboflow\n",
    "# rf = Roboflow(api_key=\"...\")\n",
    "# project = rf.workspace(\"wawan-pradana\").project(\"cinta_v2\")\n",
    "# dataset = project.version(1).download(\"yolov8\")\n",
    "# model = YOLO('yolov8n.pt')\n",
    "# results = model.train(data=\"data.yaml\", epochs=80, imgsz=416, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model Results\n",
    "<img src=\"runsSpeed/detect/train/confusion_matrix.png\" alt=\"Descrizione dell'immagine\" width=\"700\">\n",
    "<img src=\"runsTrafficLight/detect/train3/confusion_matrix.png\" alt=\"Descrizione dell'immagine\" width=\"700\">\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pretrained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"runsSpeed/detect/train/weights/best.pt\")\n",
    "modelTrafficLight = YOLO(\"runsFinLight/detect/train/weights/best.pt\")\n",
    "modelTrafficLightOver = YOLO(\"runsFinLight/detect/train/weights/best.pt\")\n",
    "\n",
    "model.to(\"cuda:0\")\n",
    "modelTrafficLight.to(\"cuda:0\")\n",
    "modelTrafficLightOver.to(\"cuda:0\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set weather conditions\n",
    "- Set the worst weather condition or the best weather condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = world.get_weather()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.sun_azimuth_angle = 0\n",
    "weather.sun_altitude_angle = -90\n",
    "weather.cloudiness = 100\n",
    "weather.precipitation = 100\n",
    "weather.precipitation_deposits = 100\n",
    "weather.wind_intensity = 100\n",
    "weather.fog_density = 100\n",
    "weather.fog_distance = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.sun_azimuth_angle = 10 \n",
    "weather.sun_altitude_angle = 60\n",
    "weather.cloudiness = 20\n",
    "weather.precipitation = 0\n",
    "weather.precipitation_deposits = 0\n",
    "weather.wind_intensity = 0\n",
    "weather.fog_density = 30\n",
    "weather.fog_distance = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.set_weather(weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions\n",
    "- **colorSpeedLimit**: Change the letters color in the view.\n",
    "- **calcColor**: Change the letters color of the traffic light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorSpeedLimit(current_speed, speed_limit):\n",
    "    if speed_limit == None or int(current_speed) <= int(speed_limit):\n",
    "        return (0, 255, 0) \n",
    "    else:\n",
    "        return (0, 0, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcColor(traffic_light):\n",
    "    if traffic_light == \"red\":\n",
    "        return (0, 0, 255)\n",
    "    elif traffic_light == \"yellow\":\n",
    "        return (0, 255, 255)\n",
    "    elif traffic_light == \"green\":\n",
    "        return (0, 255, 0)\n",
    "    else:\n",
    "        return (255, 255, 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera_callback:\n",
    "\n",
    "This function processes an image captured by a camera, analyzes it using a machine learning model, and identifies the most likely speed limit sign if found with sufficient confidence:\n",
    "\n",
    "1. **Global Variables:**\n",
    "   - `last_analysis_time`: Tracks the time of the last analysis to ensure periodic processing.\n",
    "   - `last_speed_limit`: Stores the most recently detected speed limit.\n",
    "\n",
    "2. **Image Data Conversion:**\n",
    "   - The raw image data is read into a NumPy array using `np.frombuffer`, which converts the data into a byte array.\n",
    "   - The image is reshaped into its original dimensions, including the alpha channel (RGBA format).\n",
    "   - The alpha channel is removed to work with the RGB image, creating `image_bgr`.\n",
    "\n",
    "3. **Periodic Analysis:**\n",
    "   - Checks if enough time `analysis_interval` has passed since the last analysis using the current timestamp.\n",
    "   - If the time interval condition is met, updates `last_analysis_time`.\n",
    "\n",
    "4. **Model Prediction:**\n",
    "   - The resized image is passed to a machine learning model (`model`) for analysis.\n",
    "   - Extracts the detected class IDs (`class_ids`) and their confidence scores (`confidences`) from the model's results.\n",
    "\n",
    "5. **Identify Speed Limit:**\n",
    "   - Iterates through the detected objects, finding the class ID with the highest confidence score.\n",
    "   - If the confidence score exceeds a threshold (`0.87`), determines the corresponding class name.\n",
    "\n",
    "6. **Extract Speed Limit and Notify:**\n",
    "   - Attempts to extract the speed limit value from the class name.\n",
    "   - Updates `last_speed_limit` with the detected value.\n",
    "   - Sends an event with the detected speed limit to an external broker using `sendEventToBroker`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camera_callback(image):\n",
    "    global last_speed_limit, video_output4\n",
    "\n",
    "    array = np.frombuffer(image.raw_data, dtype=np.uint8)\n",
    "    image_np = array.reshape((IMAGE_SIZE, IMAGE_SIZE, 4))\n",
    "    image_bgr = image_np[:, :, :3]\n",
    "    video_output4 = image_bgr\n",
    "\n",
    "    results = model(image_bgr, verbose=False)\n",
    "    limit_id = None\n",
    "    confidence_max = 0\n",
    "    class_ids = results[0].boxes.cls.cpu().numpy()\n",
    "    confidences = results[0].boxes.conf.cpu().numpy()\n",
    "    \n",
    "    for class_id, confidence in zip(class_ids, confidences):\n",
    "        if confidence > confidence_max:\n",
    "            limit_id = class_id\n",
    "            confidence_max = confidence\n",
    "\n",
    "    if confidence_max > 0.87:\n",
    "        class_name = class_names[int(limit_id)]\n",
    "        try:\n",
    "            if last_speed_limit == None or last_speed_limit != class_name.split(\" \")[2]:\n",
    "                sendEventToBroker(\"speedLimit\", \"Detected \" + class_name.split(\" \")[2])\n",
    "            last_speed_limit = class_name.split(\" \")[2]\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera_view_callback:\n",
    "\n",
    "This function processes an image captured by a camera, calculates the vehicle's speed, and updates the global variables used for video output and speed monitoring:\n",
    "\n",
    "1. **Global Variables:**\n",
    "   - `video_output`: A global variable used to store the processed image data for visualization or further use.\n",
    "   - `speed_car`: A global variable used to store the vehicle's current speed.\n",
    "\n",
    "2. **Speed Calculation:**\n",
    "   - Retrieves the vehicle's velocity using `vehicle.get_velocity()`, which provides the velocity components along the X, Y, and Z axes.\n",
    "   - Computes the magnitude of the velocity vector using the formula for Euclidean norm.\n",
    "   - Converts the speed from meters per second (m/s) to kilometers per hour (km/h) by multiplying by 3.6.\n",
    "   - Updates the global variable `speed_car` with the calculated speed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camera_view_callback(image):\n",
    "    global video_output, speed_car\n",
    "    array = np.frombuffer(image.raw_data, dtype=np.uint8)\n",
    "    image_np = array.reshape((height_screen, width_screen, 4))\n",
    "    velocity_car = vehicle.get_velocity()\n",
    "    speed_car = 3.6 * (velocity_car.x**2 + velocity_car.y**2 + velocity_car.z**2)**0.5\n",
    "    video_output = image_np[:, :, :3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera_traffic_callback:\n",
    "This function processes an image from a camera to detect the current state of a traffic light, applying enhancements to the image and analyzing it with a machine learning model. It updates global variables and notifies changes:\n",
    "\n",
    "1. **Global Variables:**\n",
    "   - `last_analysis_time_trafficLight`: Tracks the time of the last traffic light analysis to ensure periodic processing.\n",
    "   - `traffic_light`: Stores the detected traffic light state (`\"red\"`, `\"yellow\"`, `\"green\"`, or `\"Not detected\"`).\n",
    "\n",
    "2. **Image Data Conversion:**\n",
    "   - Converts the raw image data from the camera into a NumPy array using `np.frombuffer`.\n",
    "   - Reshapes the array into an image matrix of size `IMAGE_SIZE x IMAGE_SIZE` with 4 channels (BGRA format).\n",
    "   - Creates a copy of the RGB portion (`image_bgr`) for further processing.\n",
    "\n",
    "3. **Image Preprocessing:**\n",
    "   - **Color Enhancement:** Increases the red channel values to accentuate red tones, reduces blue and green values slightly to suppress their dominance, and creates an enhanced image for better detection.\n",
    "   - **Clipping Values:** Ensures pixel values remain in the valid range (0–255).\n",
    "\n",
    "1. **Periodic Analysis:**\n",
    "   - Checks if the interval since the last analysis exceeds a defined threshold (`analysis_interval_trafficLight`).\n",
    "   - Updates `last_analysis_time_trafficLight` when a new analysis is performed.\n",
    "\n",
    "2. **Traffic Light Detection:**\n",
    "   - Passes the processed image (`resized_image`) to a traffic light detection model (`modelTrafficLight`).\n",
    "   - Retrieves the detected class IDs (`class_ids`) and their confidence scores (`confidences`).\n",
    "   - Handles cases where no traffic lights are detected by setting `traffic_light` to `\"Not detected\"`.\n",
    "\n",
    "3. **Identify Most Likely Traffic Light:**\n",
    "   - Iterates through detected objects, identifying the class ID with the highest confidence score.\n",
    "   - It assigns the detected class name as the current traffic light state.\n",
    "   - Applies confidence thresholds:\n",
    "     - High confidence (`>0.63`) for red light.\n",
    "     - Lower confidence (`>0.47`) for other colors.\n",
    "\n",
    "4. **Update and Notify:** Sends an event to an external broker using `sendEventToBroker` with the detected traffic light state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camera_traffic_callback(image):\n",
    "    global traffic_light, video_output3\n",
    "    array = np.frombuffer(image.raw_data, dtype=np.uint8)\n",
    "    image_np = array.reshape((IMAGE_SIZE, IMAGE_SIZE, 4))\n",
    "    image_bgr = image_np[:, :, :3].copy()\n",
    "    resized_image = image_bgr.copy()\n",
    "    video_output3 = resized_image\n",
    "\n",
    "    results = modelTrafficLight(resized_image, verbose=True)\n",
    "    trafficLight_id = None\n",
    "    confidence_max = 0\n",
    "    class_ids = results[0].boxes.cls.cpu().numpy()\n",
    "    confidences = results[0].boxes.conf.cpu().numpy()\n",
    "\n",
    "    if class_ids.size == 0:\n",
    "        traffic_light = \"Not detected\"\n",
    "    else:\n",
    "        print(str(class_ids.size))\n",
    "        for class_id, confidence in zip(class_ids, confidences):\n",
    "            if confidence > confidence_max:\n",
    "                trafficLight_id = class_id\n",
    "                confidence_max = confidence\n",
    "\n",
    "        if traffic_light != None and class_names_trafficLight[int(trafficLight_id)] == \"yellow\" and traffic_light == \"red\":\n",
    "            class_name = \"red\"\n",
    "        else:\n",
    "            class_name = class_names_trafficLight[int(trafficLight_id)]\n",
    "        if confidence_max > 0.55 and class_name==\"red\" or confidence_max > 0.50 and class_name==\"green\" or confidence_max > 0.50 and class_name==\"yellow\":\n",
    "            # print(confidence_max)\n",
    "            if traffic_light != class_name:\n",
    "                traffic_light = class_name\n",
    "                sendEventToBroker(\"TrafficLight\", \"Detected trafficlight \" + class_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera_traffic_red_callback:\n",
    "\n",
    "This function operates similarly to `camera_traffic_callback(image)` but focuses specifically on detecting and reacting to **red traffic lights**, modifying a global flag (`red_over`) based on the detection results:\n",
    "\n",
    "1. **Global Variables:**\n",
    "   - `last_analysis_time_trafficLight_red`: Tracks the time of the last analysis for red traffic lights to ensure periodic updates.\n",
    "   - `red_over`: A flag indicating whether a red light condition has been detected and action of stopping should be enforced.\n",
    "\n",
    "2. **Traffic Light Detection:**\n",
    "   - Passes the processed image to the `modelTrafficLight`, which detects traffic light states and outputs class IDs (`class_ids`) and their confidence scores (`confidences`).\n",
    "   - Handles cases where no traffic lights are detected by resetting `red_over` to `False`.\n",
    "\n",
    "3. **Red Light Detection Logic:**\n",
    "   - Iterates through detected objects, identifying the class ID with the highest confidence score.\n",
    "   - If the detected class is `\"red\"` and the confidence score exceeds `0.65`: Sets `red_over` to `True` **unless the vehicle is in reverse (`gear != \"Reverse\"`)** or another condition prevents it.\n",
    "   - If the detected class is `\"green\"` or `\"yellow\"` and the confidence score exceeds `0.43`: Resets `red_over` to `False`, allowing movement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camera_traffic_red_callback(image):\n",
    "    global red_over, video_output2\n",
    "    array = np.frombuffer(image.raw_data, dtype=np.uint8)\n",
    "    image_np = array.reshape((IMAGE_SIZE, IMAGE_SIZE, 4))\n",
    "    image_bgr = image_np[:, :, :3].copy()\n",
    "    resized_image = image_bgr.copy()\n",
    "    video_output2 = resized_image\n",
    "\n",
    "    results = modelTrafficLightOver(resized_image, verbose=False)\n",
    "\n",
    "    trafficLight_id = None\n",
    "    confidence_max = 0\n",
    "\n",
    "    class_ids = results[0].boxes.cls.cpu().numpy()\n",
    "    confidences = results[0].boxes.conf.cpu().numpy()\n",
    "\n",
    "    if class_ids.size != 0:\n",
    "        for class_id, confidence in zip(class_ids, confidences):\n",
    "            if confidence > confidence_max:\n",
    "                trafficLight_id = class_id\n",
    "                confidence_max = confidence\n",
    "\n",
    "        class_name = class_names_trafficLight[int(trafficLight_id)]\n",
    "        if class_name==\"red\" and confidence_max > 0.50:\n",
    "            if(gear != \"Reverse\" and not red_over):\n",
    "                red_over = True\n",
    "        elif (class_name==\"green\" or class_name==\"yellow\") and confidence_max > 0.43:\n",
    "            red_over = False\n",
    "    else:\n",
    "        red_over = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activate_hazard_lights():\n",
    "    global hazard_lights_active, hazard_lights_start_time\n",
    "    hazard_lights_active = True\n",
    "    hazard_lights_start_time = time.time()\n",
    "    vehicle.set_light_state(carla.VehicleLightState(carla.VehicleLightState.RightBlinker | carla.VehicleLightState.LeftBlinker))\n",
    "\n",
    "def deactivate_hazard_lights():\n",
    "    global hazard_lights_active\n",
    "    hazard_lights_active = False\n",
    "    vehicle.set_light_state(carla.VehicleLightState.NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printTextOnScreen(temp_frame, text, position, color):\n",
    "    cv2.putText(\n",
    "        temp_frame,\n",
    "        text,\n",
    "        position,\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        0.5,\n",
    "        color,\n",
    "        2,\n",
    "        cv2.LINE_AA,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkRedOver(val):\n",
    "    if red_over:\n",
    "        if val != \"You ran a red light\":\n",
    "            sendEventToBroker(\"TrafficLightViolation\", \"Red light violation\")\n",
    "        return \"You ran a red light\"\n",
    "    else:\n",
    "        return \"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configparser import ConfigParser\n",
    "import math\n",
    "\n",
    "pygame.joystick.init()\n",
    "joystick_count = pygame.joystick.get_count()\n",
    "if joystick_count > 1:\n",
    "    raise ValueError(\"Please Connect Just One Joystick\")\n",
    "\n",
    "joystick = pygame.joystick.Joystick(0)\n",
    "joystick.init()\n",
    "\n",
    "parser = ConfigParser()\n",
    "\n",
    "parser.read('.\\wheel_config.ini')\n",
    "steer_idx = int(\n",
    "parser.get('G29 Racing Wheel', 'steering_wheel'))\n",
    "throttle_idx = int(\n",
    "parser.get('G29 Racing Wheel', 'throttle'))\n",
    "brake_idx = int(parser.get('G29 Racing Wheel', 'brake'))\n",
    "reverse_idx = int(parser.get('G29 Racing Wheel', 'reverse'))\n",
    "handbrake_idx = int(\n",
    "parser.get('G29 Racing Wheel', 'handbrake'))\n",
    "\n",
    "\n",
    "\n",
    "numAxes = joystick.get_numaxes()\n",
    "jsInputs = [float(joystick.get_axis(i)) for i in range(numAxes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 (no detections), 60.3ms\n",
      "Speed: 3.5ms preprocess, 60.3ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 27.0ms\n",
      "Speed: 1.5ms preprocess, 27.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 18.0ms\n",
      "Speed: 2.0ms preprocess, 18.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 17.5ms\n",
      "Speed: 2.5ms preprocess, 17.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.1ms\n",
      "Speed: 2.5ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.1ms\n",
      "Speed: 3.0ms preprocess, 14.1ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 18.9ms\n",
      "Speed: 2.0ms preprocess, 18.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 19.0ms\n",
      "Speed: 3.0ms preprocess, 19.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.2ms\n",
      "Speed: 4.5ms preprocess, 15.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.6ms\n",
      "Speed: 3.0ms preprocess, 15.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 24.5ms\n",
      "Speed: 2.0ms preprocess, 24.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 16.5ms\n",
      "Speed: 2.5ms preprocess, 16.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 19.0ms\n",
      "Speed: 3.1ms preprocess, 19.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 18.5ms\n",
      "Speed: 2.5ms preprocess, 18.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 18.5ms\n",
      "Speed: 2.5ms preprocess, 18.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.5ms\n",
      "Speed: 2.5ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 18.5ms\n",
      "Speed: 3.0ms preprocess, 18.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.5ms\n",
      "Speed: 3.0ms preprocess, 15.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 24.2ms\n",
      "Speed: 5.0ms preprocess, 24.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.3ms\n",
      "Speed: 5.0ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 38.3ms\n",
      "Speed: 3.0ms preprocess, 38.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 36.1ms\n",
      "Speed: 3.0ms preprocess, 36.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 41.1ms\n",
      "Speed: 4.0ms preprocess, 41.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 18.9ms\n",
      "Speed: 3.0ms preprocess, 18.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 20.0ms\n",
      "Speed: 3.5ms preprocess, 20.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.5ms\n",
      "Speed: 3.5ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 27.1ms\n",
      "Speed: 2.0ms preprocess, 27.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 24.6ms\n",
      "Speed: 2.0ms preprocess, 24.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 24.0ms\n",
      "Speed: 3.0ms preprocess, 24.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 18.6ms\n",
      "Speed: 3.0ms preprocess, 18.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 18.6ms\n",
      "Speed: 4.0ms preprocess, 18.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.5ms\n",
      "Speed: 5.5ms preprocess, 15.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.0ms\n",
      "Speed: 3.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 21.5ms\n",
      "Speed: 3.0ms preprocess, 21.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 24.3ms\n",
      "Speed: 3.0ms preprocess, 24.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 34.4ms\n",
      "Speed: 3.0ms preprocess, 34.4ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 17.8ms\n",
      "Speed: 4.0ms preprocess, 17.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 18.0ms\n",
      "Speed: 3.0ms preprocess, 18.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 20.0ms\n",
      "Speed: 3.0ms preprocess, 20.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.0ms\n",
      "Speed: 5.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 30.5ms\n",
      "Speed: 3.0ms preprocess, 30.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 30.1ms\n",
      "Speed: 4.5ms preprocess, 30.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 17.5ms\n",
      "Speed: 2.5ms preprocess, 17.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 red, 20.0ms\n",
      "Speed: 4.5ms preprocess, 20.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 (no detections), 18.9ms\n",
      "Speed: 3.0ms preprocess, 18.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 18.5ms\n",
      "Speed: 2.5ms preprocess, 18.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 27.6ms\n",
      "Speed: 4.0ms preprocess, 27.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 34.0ms\n",
      "Speed: 6.3ms preprocess, 34.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 red, 14.5ms\n",
      "Speed: 4.0ms preprocess, 14.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 18.0ms\n",
      "Speed: 5.0ms preprocess, 18.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 15.5ms\n",
      "Speed: 4.5ms preprocess, 15.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 19.0ms\n",
      "Speed: 3.0ms preprocess, 19.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 19.0ms\n",
      "Speed: 5.0ms preprocess, 19.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 30.2ms\n",
      "Speed: 4.5ms preprocess, 30.2ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 17.6ms\n",
      "Speed: 3.0ms preprocess, 17.6ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 17.5ms\n",
      "Speed: 3.5ms preprocess, 17.5ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 22.0ms\n",
      "Speed: 5.2ms preprocess, 22.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 21.5ms\n",
      "Speed: 2.0ms preprocess, 21.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 31.5ms\n",
      "Speed: 5.5ms preprocess, 31.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 36.8ms\n",
      "Speed: 3.0ms preprocess, 36.8ms inference, 7.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 18.2ms\n",
      "Speed: 3.0ms preprocess, 18.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 20.8ms\n",
      "Speed: 2.5ms preprocess, 20.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 15.0ms\n",
      "Speed: 2.2ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 17.0ms\n",
      "Speed: 3.0ms preprocess, 17.0ms inference, 6.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 19.8ms\n",
      "Speed: 5.0ms preprocess, 19.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 16.5ms\n",
      "Speed: 2.1ms preprocess, 16.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 24.5ms\n",
      "Speed: 3.0ms preprocess, 24.5ms inference, 12.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 27.4ms\n",
      "Speed: 8.5ms preprocess, 27.4ms inference, 10.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 20.5ms\n",
      "Speed: 4.0ms preprocess, 20.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 18.2ms\n",
      "Speed: 2.0ms preprocess, 18.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 15.5ms\n",
      "Speed: 3.0ms preprocess, 15.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 20.5ms\n",
      "Speed: 3.0ms preprocess, 20.5ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 19.6ms\n",
      "Speed: 3.0ms preprocess, 19.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 19.0ms\n",
      "Speed: 3.0ms preprocess, 19.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 29.5ms\n",
      "Speed: 3.0ms preprocess, 29.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 18.9ms\n",
      "Speed: 2.0ms preprocess, 18.9ms inference, 6.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 23.0ms\n",
      "Speed: 2.5ms preprocess, 23.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 green, 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 green, 17.0ms\n",
      "Speed: 4.0ms preprocess, 17.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 green, 15.1ms\n",
      "Speed: 3.5ms preprocess, 15.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 green, 33.1ms\n",
      "Speed: 4.5ms preprocess, 33.1ms inference, 10.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 green, 16.5ms\n",
      "Speed: 2.5ms preprocess, 16.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 green, 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 green, 20.0ms\n",
      "Speed: 3.5ms preprocess, 20.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 green, 15.5ms\n",
      "Speed: 3.4ms preprocess, 15.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 green, 18.5ms\n",
      "Speed: 3.5ms preprocess, 18.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 green, 31.0ms\n",
      "Speed: 4.5ms preprocess, 31.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 green, 29.5ms\n",
      "Speed: 12.0ms preprocess, 29.5ms inference, 10.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 green, 16.8ms\n",
      "Speed: 3.0ms preprocess, 16.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 green, 19.0ms\n",
      "Speed: 3.0ms preprocess, 19.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 green, 14.5ms\n",
      "Speed: 3.0ms preprocess, 14.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 green, 22.3ms\n",
      "Speed: 3.5ms preprocess, 22.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 green, 19.1ms\n",
      "Speed: 3.5ms preprocess, 19.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 green, 18.0ms\n",
      "Speed: 3.0ms preprocess, 18.0ms inference, 9.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 green, 20.6ms\n",
      "Speed: 4.0ms preprocess, 20.6ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 green, 37.6ms\n",
      "Speed: 3.4ms preprocess, 37.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 green, 14.5ms\n",
      "Speed: 4.0ms preprocess, 14.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 green, 18.0ms\n",
      "Speed: 3.0ms preprocess, 18.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 green, 18.6ms\n",
      "Speed: 3.0ms preprocess, 18.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 green, 21.1ms\n",
      "Speed: 2.5ms preprocess, 21.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 green, 24.0ms\n",
      "Speed: 3.0ms preprocess, 24.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 green, 21.0ms\n",
      "Speed: 3.0ms preprocess, 21.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 green, 24.3ms\n",
      "Speed: 5.0ms preprocess, 24.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 green, 15.5ms\n",
      "Speed: 3.0ms preprocess, 15.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 green, 18.4ms\n",
      "Speed: 3.5ms preprocess, 18.4ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 yellow, 20.0ms\n",
      "Speed: 2.0ms preprocess, 20.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 yellow, 15.2ms\n",
      "Speed: 3.0ms preprocess, 15.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 yellow, 23.0ms\n",
      "Speed: 2.0ms preprocess, 23.0ms inference, 6.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 yellow, 35.5ms\n",
      "Speed: 3.0ms preprocess, 35.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 yellow, 22.0ms\n",
      "Speed: 9.5ms preprocess, 22.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 yellow, 17.6ms\n",
      "Speed: 3.0ms preprocess, 17.6ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 yellow, 20.0ms\n",
      "Speed: 5.5ms preprocess, 20.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 yellow, 14.8ms\n",
      "Speed: 3.0ms preprocess, 14.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 yellow, 18.0ms\n",
      "Speed: 3.0ms preprocess, 18.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 19.6ms\n",
      "Speed: 3.0ms preprocess, 19.6ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 42.1ms\n",
      "Speed: 5.0ms preprocess, 42.1ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 20.6ms\n",
      "Speed: 4.0ms preprocess, 20.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 20.0ms\n",
      "Speed: 3.0ms preprocess, 20.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 14.6ms\n",
      "Speed: 3.0ms preprocess, 14.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 17.1ms\n",
      "Speed: 4.0ms preprocess, 17.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 18.0ms\n",
      "Speed: 2.3ms preprocess, 18.0ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 20.4ms\n",
      "Speed: 4.5ms preprocess, 20.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 39.1ms\n",
      "Speed: 3.5ms preprocess, 39.1ms inference, 12.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 19.6ms\n",
      "Speed: 4.0ms preprocess, 19.6ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 19.0ms\n",
      "Speed: 3.0ms preprocess, 19.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 15.6ms\n",
      "Speed: 3.0ms preprocess, 15.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 18.1ms\n",
      "Speed: 3.5ms preprocess, 18.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 24.6ms\n",
      "Speed: 2.3ms preprocess, 24.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 16.5ms\n",
      "Speed: 3.5ms preprocess, 16.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 20.1ms\n",
      "Speed: 8.5ms preprocess, 20.1ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 36.8ms\n",
      "Speed: 3.5ms preprocess, 36.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 29.6ms\n",
      "Speed: 2.5ms preprocess, 29.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 20.9ms\n",
      "Speed: 4.0ms preprocess, 20.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 18.0ms\n",
      "Speed: 2.0ms preprocess, 18.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 21.0ms\n",
      "Speed: 4.0ms preprocess, 21.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 15.6ms\n",
      "Speed: 3.0ms preprocess, 15.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 29.6ms\n",
      "Speed: 3.0ms preprocess, 29.6ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 24.0ms\n",
      "Speed: 3.5ms preprocess, 24.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 19.0ms\n",
      "Speed: 2.5ms preprocess, 19.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 16.5ms\n",
      "Speed: 3.0ms preprocess, 16.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 19.6ms\n",
      "Speed: 4.0ms preprocess, 19.6ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 24.0ms\n",
      "Speed: 2.5ms preprocess, 24.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 22.0ms\n",
      "Speed: 3.0ms preprocess, 22.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 20.7ms\n",
      "Speed: 3.1ms preprocess, 20.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 24.5ms\n",
      "Speed: 4.0ms preprocess, 24.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 18.0ms\n",
      "Speed: 3.0ms preprocess, 18.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 16.0ms\n",
      "Speed: 10.0ms preprocess, 16.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 18.0ms\n",
      "Speed: 3.0ms preprocess, 18.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 16.0ms\n",
      "Speed: 5.5ms preprocess, 16.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 18.6ms\n",
      "Speed: 3.0ms preprocess, 18.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 41.1ms\n",
      "Speed: 2.5ms preprocess, 41.1ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 15.5ms\n",
      "Speed: 3.0ms preprocess, 15.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 18.0ms\n",
      "Speed: 3.0ms preprocess, 18.0ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 21.0ms\n",
      "Speed: 2.5ms preprocess, 21.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 19.0ms\n",
      "Speed: 4.0ms preprocess, 19.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 18.5ms\n",
      "Speed: 2.5ms preprocess, 18.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 30.6ms\n",
      "Speed: 4.0ms preprocess, 30.6ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 36.6ms\n",
      "Speed: 3.0ms preprocess, 36.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 25.1ms\n",
      "Speed: 3.0ms preprocess, 25.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 18.0ms\n",
      "Speed: 3.0ms preprocess, 18.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 18.0ms\n",
      "Speed: 3.0ms preprocess, 18.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 19.0ms\n",
      "Speed: 4.0ms preprocess, 19.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 36.1ms\n",
      "Speed: 3.0ms preprocess, 36.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 red, 18.9ms\n",
      "Speed: 3.0ms preprocess, 18.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "displayCommand = pygame.display.set_mode((200, 100))\n",
    "\n",
    "pygame.display.set_caption(\"Manual Control CARLA\")\n",
    "\n",
    "hazard_lights_active = False\n",
    "hazard_lights_start_time = 0\n",
    "\n",
    "# Define control variables and increments\n",
    "steer_increment = 0.02  # Increment for steering adjustments\n",
    "throttle_increment = 0.1  # Increment for throttle adjustments\n",
    "steer = 0.0  # Current steering value\n",
    "throttle = 0.0  # Current throttle value\n",
    "brake = 0.0  # Current brake value\n",
    "global gear  # Define a global gear variable\n",
    "gear = \"Drive\"  # Initial gear state\n",
    "speed_control_activate = False  # Flag for speed control activation\n",
    "auto_pilot_activate = False  # Flag for autopilot activation\n",
    "red_over_activate = False  # Flag for red light detection activation\n",
    "red_over = False  # Red light violation flag\n",
    "global control # Set the car control\n",
    "val = \"\"\n",
    "\n",
    "# Constants for proportional controller\n",
    "KP_THROTTLE = 0.15  # Proportional gain for acceleration\n",
    "KP_BRAKE = 0.02  # Proportional gain for braking\n",
    "DEAD_ZONE = 3.0  # Dead zone around the speed limit\n",
    "MIN_THROTTLE = 0.2  # Minimum throttle value\n",
    "MIN_BRAKE = 0.1  # Minimum brake value\n",
    "\n",
    "# Initialize the output video frame\n",
    "video_output = np.zeros((width_screen, height_screen, 3), dtype=np.uint8)\n",
    "\n",
    "# Variables for speed and traffic light tracking\n",
    "last_speed_limit = None  # Last detected speed limit\n",
    "speed_car = 0  # Current vehicle speed\n",
    "traffic_light = \"Not detected\"  # Current traffic light state\n",
    "\n",
    "# Load class names for object detection models\n",
    "class_names = model.names  # Object detection model names\n",
    "class_names_trafficLight = modelTrafficLight.names  # Traffic light model names\n",
    "\n",
    "# Spawn the simulated vehicle\n",
    "vehicle = spawn_vehicle()\n",
    "sun_altitude = weather.sun_altitude_angle\n",
    "if sun_altitude < 10:\n",
    "    vehicle.set_light_state(carla.VehicleLightState.HighBeam)\n",
    "else: \n",
    "    vehicle.set_light_state(carla.VehicleLightState.NONE)\n",
    "\n",
    "\n",
    "# Attach and configure cameras for various purposes\n",
    "speed_limit_camera = spawn_camera(attach_to=vehicle, sensor_tick=0.2)  # Main camera\n",
    "speed_limit_camera.listen(lambda image: camera_callback(image))  # Listen for incoming frames\n",
    "\n",
    "camera_view = spawn_camera(\n",
    "    attach_to=vehicle, \n",
    "    sensor_tick=0.0,\n",
    "    transform=carla.Transform(carla.Location(x=1, z=1.5), carla.Rotation(pitch=0, yaw=0)), \n",
    "    width=width_screen, \n",
    "    height=height_screen, \n",
    "    foV=70\n",
    ")  # Driver's perspective camera\n",
    "camera_view.listen(lambda image: camera_view_callback(image))\n",
    "\n",
    "# Additional cameras for traffic light and red light detection\n",
    "if currect_map:\n",
    "    trafficLight_camera = spawn_camera(\n",
    "        attach_to=vehicle, \n",
    "        sensor_tick=0.35,\n",
    "        transform=carla.Transform(carla.Location(x=0.3, y=1, z=1.2), carla.Rotation(pitch=5, yaw=0)), \n",
    "        width=IMAGE_SIZE, \n",
    "        height=IMAGE_SIZE, \n",
    "        foV=40,\n",
    "    )\n",
    "    trafficLight_camera.listen(lambda image: camera_traffic_callback(image))\n",
    "    \n",
    "    trafficLight_red_camera = spawn_camera(\n",
    "        attach_to=vehicle,\n",
    "        sensor_tick=0.35,\n",
    "        transform=carla.Transform(carla.Location(x=-1.5, y=0, z=2), carla.Rotation(pitch=0, yaw=0)), \n",
    "        width=IMAGE_SIZE, \n",
    "        height=IMAGE_SIZE, \n",
    "        foV=110\n",
    "    )\n",
    "    trafficLight_red_camera.listen(lambda image: camera_traffic_red_callback(image))\n",
    "\n",
    "# Create an OpenCV window for displaying results\n",
    "cv2.namedWindow('RGB Camera', cv2.WINDOW_FULLSCREEN)\n",
    "cv2.namedWindow('RGB Camera1', cv2.WINDOW_NORMAL)\n",
    "cv2.namedWindow('RGB Camera2', cv2.WINDOW_NORMAL)\n",
    "cv2.namedWindow('RGB Camera3', cv2.WINDOW_NORMAL)\n",
    "\n",
    "try:\n",
    "    clock = pygame.time.Clock()  # Pygame clock for controlling loop rate\n",
    "    event_timer = 0  # Timer for event processing\n",
    "    EVENT_RATE = 100  # Event handling interval in milliseconds\n",
    "\n",
    "    while True:\n",
    "        time_hazard = time.time()\n",
    "        jsInputs = [float(joystick.get_axis(i)) for i in range(numAxes)]\n",
    "        # Add text overlays to the output frame\n",
    "        temp_frame = video_output.copy()\n",
    "        printTextOnScreen(temp_frame, f\"Last Speed Limit: {last_speed_limit}\", (10, 20), (0, 255, 0))\n",
    "        printTextOnScreen(temp_frame, f\"Current speed: {speed_car:.0f}\", (10, 45), colorSpeedLimit(speed_car, last_speed_limit))\n",
    "        printTextOnScreen(temp_frame, f\"Gear: {gear}\", (10, 100), (255, 255, 255))\n",
    "        printTextOnScreen(temp_frame,  f\"C Autopilot: {auto_pilot_activate}\", (10, 130), (255, 255, 255))\n",
    "        printTextOnScreen(temp_frame, f\"E SpeedControl: {speed_control_activate}\", (10, 160), (255, 255, 255))\n",
    "        printTextOnScreen(temp_frame,  f\"O Red Over Automatic Brake: {red_over_activate}\", (10, 190), (255, 255, 255))\n",
    "        printTextOnScreen(temp_frame,  f\"Traffic light: {traffic_light}\", (10, 70), calcColor(traffic_light))\n",
    "        val = checkRedOver(val)\n",
    "        printTextOnScreen(temp_frame,  val, (10, 220), (0, 0, 255))\n",
    "\n",
    "        # Show the frame with overlays\n",
    "        cv2.imshow('RGB Camera', temp_frame)\n",
    "        cv2.imshow('RGB Camera1', video_output2.copy())\n",
    "        cv2.imshow('RGB Camera2', video_output3.copy())\n",
    "        cv2.imshow('RGB Camera3', video_output4.copy())\n",
    "\n",
    "        # Break the loop on 'q' key press\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "\n",
    "        # Handle Pygame events periodically\n",
    "        current_time = pygame.time.get_ticks()\n",
    "        if current_time - event_timer > EVENT_RATE:\n",
    "            event_timer = current_time\n",
    "            for event in pygame.event.get():\n",
    "                if event.type == pygame.QUIT:\n",
    "                    break\n",
    "                elif event.type == pygame.KEYUP:  # Handle key releases\n",
    "                    if event.key == pygame.K_e:  # Toggle speed control\n",
    "                        speed_control_activate = not speed_control_activate\n",
    "                    if event.key == pygame.K_c:  # Enable autopilot\n",
    "                        auto_pilot_activate = not auto_pilot_activate\n",
    "                        vehicle.set_autopilot(auto_pilot_activate)\n",
    "                    if event.key == pygame.K_o:  # Toggle red light detection\n",
    "                        red_over_activate = not red_over_activate\n",
    "\n",
    "            keys = pygame.key.get_pressed()  # Get pressed keys\n",
    "\n",
    "            K2 = 1.6  # 1.6\n",
    "            if jsInputs[throttle_idx] == 0.0:\n",
    "                throttleCmd = 0\n",
    "            else:\n",
    "                throttleCmd =  K2 + (2.05 * math.log10(0.7 * jsInputs[throttle_idx] + 1.4) - 1.2) / 0.92\n",
    "                if throttleCmd <= 0:\n",
    "                    throttleCmd = 0\n",
    "                elif throttleCmd > 1:\n",
    "                    throttleCmd = 1\n",
    "\n",
    "            # Handle speed control logic\n",
    "            if speed_control_activate and last_speed_limit and throttleCmd>0.1:\n",
    "                # Calculate speed error relative to the limit\n",
    "                error = float(last_speed_limit) - float(speed_car) + 3\n",
    "                if error < -DEAD_ZONE:\n",
    "                    throttle = 0\n",
    "                    brake = max(KP_BRAKE * abs(error), MIN_BRAKE)\n",
    "                else:\n",
    "                    throttle = throttleCmd\n",
    "                    brake = 0\n",
    "            if speed_control_activate and last_speed_limit and keys[pygame.K_w]:\n",
    "                # Calculate speed error relative to the limit\n",
    "                error = float(last_speed_limit) - float(speed_car) + 3\n",
    "                if error < -DEAD_ZONE:\n",
    "                    throttle = 0\n",
    "                    brake = max(KP_BRAKE * abs(error), MIN_BRAKE)\n",
    "                else:\n",
    "                    throttle = max(KP_THROTTLE * error, MIN_THROTTLE)\n",
    "                    brake = 0\n",
    "            elif keys[pygame.K_w]:  # Manual throttle control\n",
    "                throttle = min(throttle + throttle_increment, 1)\n",
    "                brake = 0\n",
    "            elif throttleCmd>0.1:\n",
    "                throttle = throttleCmd\n",
    "                brake=0\n",
    "            else:\n",
    "                throttle = 0\n",
    "                brake = 0\n",
    "            \n",
    "            brakeCmd = jsInputs[brake_idx]#1.6 + (2.05 * math.log10(0.7 * jsInputs[brake_idx] + 1.4) - 1.2) / 0.92\n",
    "            if brakeCmd <= 0:\n",
    "                brakeCmd = 0\n",
    "            elif brakeCmd > 1:\n",
    "                brakeCmd = 1\n",
    "            \n",
    "            if brakeCmd>0.1:\n",
    "                brake = brakeCmd\n",
    "                throttle = 0\n",
    "            elif keys[pygame.K_s]:  # Manual brake control\n",
    "                brake = min(brake + throttle_increment * 4, 1)\n",
    "                throttle = 0\n",
    "\n",
    "            if red_over and int(speed_car) <= 40 and gear != \"Reverse\" and red_over_activate:\n",
    "                activate_hazard_lights()\n",
    "                brake = 1\n",
    "                throttle = 0\n",
    "\n",
    "            # Handle steering controls\n",
    "            if keys[pygame.K_r]:  # Reverse gear\n",
    "                gear = \"Reverse\"\n",
    "                red_over = False\n",
    "            elif keys[pygame.K_f]:  # Forward gear\n",
    "                gear = \"Drive\"\n",
    "            elif keys[pygame.K_a]:  # Steer left\n",
    "                steer = max(steer - steer_increment, -1)\n",
    "            elif keys[pygame.K_d]:  # Steer right\n",
    "                steer = min(steer + steer_increment, 1)\n",
    "            else:\n",
    "                if joystick_count == 1:\n",
    "                    K1 = 1.0  \n",
    "                    steer = jsInputs[steer_idx]#K1 * math.tan(1.1 * jsInputs[steer_idx])\n",
    "                else:\n",
    "                    steer = steer * 0.9  # Gradually return to center\n",
    "\n",
    "            if hazard_lights_active and (time_hazard - hazard_lights_start_time > 2):\n",
    "                deactivate_hazard_lights()\n",
    "\n",
    "            control = carla.VehicleControl()\n",
    "            control.throttle = throttle\n",
    "            control.brake = brake\n",
    "            control.steer = steer\n",
    "            control.reverse = (gear == \"Reverse\")\n",
    "            vehicle.apply_control(control)\n",
    "\n",
    "        clock.tick(40)  # Maintain a 40 FPS loop rate\n",
    "finally:\n",
    "    # Clean up resources and connections\n",
    "    cv2.destroyAllWindows()\n",
    "    pygame.quit()\n",
    "    speed_limit_camera.destroy()\n",
    "    trafficLight_camera.destroy()\n",
    "    trafficLight_red_camera.destroy()\n",
    "    camera_view.destroy()\n",
    "    vehicle.destroy()\n",
    "    clientMQTT.disconnect()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carla-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
